{"llama_cache": {"aa45e310c7c8ae1ddf933f65f083b881f7c65a815d3fc800df71cb5916f29a47": {"nodes": [{"__data__": {"id_": "a7d67b37-04a6-4dc9-bcd4-26d31fde6c44", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cc23039-683e-42ff-b4ba-404a92677b1d", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "9bae910b07e00ab8140e86243b92eb959c0240aadcc5c5c68c84722d31cb1c86", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# From Local to Global: A Graph RAG Approach to Query-Focused Summarization\n\nDarren Edge1\u2020 Ha Trinh1\u2020 Newman Cheng2 Joshua Bradley2 Alex Chao3\n\narXiv:2404.16130v1 [cs.CL] 24 Apr 2024 Apurva Mody3 Steven Truitt2 Jonathan Larson1\n\n1Microsoft Research\n\n2Microsoft Strategic Missions and Technologies\n\n3Microsoft Office of the CTO\n\n{daedge,trinhha,newmancheng,joshbradley,achao,moapurva,steventruitt,jolarso}@microsoft.com\n\n\u2020These authors contributed equally to this work\n\n# Abstract\n\nThe use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as \u201cWhat are the main themes in the dataset?\u201d, since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed. Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that Graph RAG leads to substantial improvements over a na\u00efve RAG baseline for both the comprehensiveness and diversity of generated answers. An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\n\n# 1 Introduction\n\nHuman endeavors across a range of domains rely on our ability to read and reason about large collections of documents, often reaching conclusions that go beyond anything stated in the source texts themselves. With the emergence of large language models (LLMs), we are already witnessing attempts to automate human-like sensemaking in complex domains like scientific discovery (Microsoft, 2023) and intelligence analysis (Ranade and Joshi, 2023), where sensemaking is defined as\n\nPreprint. Under review.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2569, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "0722d552-97ea-4a86-bfad-9a3ed9bf8740", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "47a66a1a-6d36-4f9e-bafe-bcbc99e118ca", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "0d98989d455f942df670f85f81116f71a4d5aa2ab3c8b201201d85b4e4ad98f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Source Documents\n\n# Global Answer\n\n# text extraction\n\n# and chunking\n\n# Text Chunks\n\n# domain-tailored\n\n# summarization\n\n# Community Answers\n\n# query-focused\n\n# summarization\n\n# Community Summaries\n\n# domain-tailored\n\n# summarization\n\n# community\n\n# detection\n\n# Graph Communities\n\nIndexing Time\nPipeline Stage\nQuery Time\nFigure 1: Graph RAG pipeline using an LLM-derived graph index of source document text. This index spans nodes (e.g., entities), edges (e.g., relationships), and covariates (e.g., claims) that have been detected, extracted, and summarized by LLM prompts tailored to the domain of the dataset. Community detection (e.g., Leiden, Traag et al., 2019) is used to partition the graph index into groups of elements (nodes, edges, covariates) that the LLM can summarize in parallel at both indexing time and query time. The \u201cglobal answer\u201d to a given query is produced using a final round of query-focused summarization over all community summaries reporting relevance to that query.\n\n\u201ca motivated, continuous effort to understand connections (which can be among people, places, and events) in order to anticipate their trajectories and act effectively\u201d (Klein et al., 2006a). Supporting human-led sensemaking over entire text corpora, however, needs a way for people to both apply and refine their mental model of the data (Klein et al., 2006b) by asking questions of a global nature. Retrieval-augmented generation (RAG, Lewis et al., 2020) is an established approach to answering user questions over entire datasets, but it is designed for situations where these answers are contained locally within regions of text whose retrieval provides sufficient grounding for the generation task.\n\nInstead, a more appropriate task framing is query-focused summarization (QFS, Dang, 2006), and in particular, query-focused abstractive summarization that generates natural language summaries and not just concatenated excerpts (Baumel et al., 2018; Laskar et al., 2020; Yao et al., 2017). In recent years, however, such distinctions between summarization tasks that are abstractive versus extractive, generic versus query-focused, and single-document versus multi-document, have become less relevant. While early applications of the transformer architecture showed substantial improvements on the state-of-the-art for all such summarization tasks (Goodwin et al., 2020; Laskar et al., 2022; Liu and Lapata, 2019), these tasks are now trivialized by modern LLMs, including the GPT (Achiam et al., 2023; Brown et al., 2020), Llama (Touvron et al., 2023), and Gemini (Anil et al., 2023) series, all of which can use in-context learning to summarize any content provided in their context window.\n\nThe challenge remains, however, for query-focused abstractive summarization over an entire corpus. Such volumes of text can greatly exceed the limits of LLM context windows, and the expansion of such windows may not be enough given that information can be \u201clost in the middle\u201d of longer contexts (Kuratov et al., 2024; Liu et al., 2023). In addition, although the direct retrieval of text chunks in na\u00efve RAG is likely inadequate for QFS tasks, it is possible that an alternative form of pre-indexing could support a new RAG approach specifically targeting global summarization.\n\nIn this paper, we present a Graph RAG approach based on global summarization of an LLM-derived knowledge graph (Figure 1). In contrast with related work that exploits the structured retrieval and traversal affordances of graph indexes (subsection 4.2), we focus on a previously unexplored quality of graphs in this context: their inherent modularity (Newman, 2006) and the ability of community detection algorithms to partition graphs into modular communities of closely-related nodes (e.g., Louvain, Blondel et al., 2008; Leiden, Traag et al., 2019). LLM-generated summaries of these", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3864, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "a7badba9-3d3b-4e72-a766-db7d7c8814f8", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "276af327-93a9-4532-aa29-c486b5f30cab", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "c2145fd838d089d74f0652df224e5f18629ac6d1fec1a2283cf9ca6f0b8cb76a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Entity references detected\n\n|30000|600 chunk size| | | |\n|---|---|---|---|---|\n|20000|2400 chunk size| | | |\n|10000| | | | |\n|0|0|1|2|3|\n\nFigure 2: How the entity references detected in the HotPotQA dataset (Yang et al., 2018) varies with chunk size and gleanings for our generic entity extraction prompt with gpt-4-turbo.\n\nCommunity descriptions provide complete coverage of the underlying graph index and the input documents it represents. Query-focused summarization of an entire corpus is then made possible using a map-reduce approach: first using each community summary to answer the query independently and in parallel, then summarizing all relevant partial answers into a final global answer.\n\nTo evaluate this approach, we used an LLM to generate a diverse set of activity-centered sense-making questions from short descriptions of two representative real-world datasets, containing podcast transcripts and news articles respectively. For the target qualities of comprehensiveness, diversity, and empowerment (defined in subsection 3.4) that develop understanding of broad issues and themes, we both explore the impact of varying the hierarchical level of community summaries used to answer queries, as well as compare to na\u00efve RAG and global map-reduce summarization of source texts. We show that all global approaches outperform na\u00efve RAG on comprehensiveness and diversity, and that Graph RAG with intermediate- and low-level community summaries shows favorable performance over source text summarization on these same metrics, at lower token costs.\n\n# 2 Graph RAG Approach & Pipeline\n\nWe now unpack the high-level data flow of the Graph RAG approach (Figure 1) and pipeline, describing key design parameters, techniques, and implementation details for each step.\n\n# 2.1 Source Documents \u2192 Text Chunks\n\nA fundamental design decision is the granularity with which input texts extracted from source documents should be split into text chunks for processing. In the following step, each of these chunks will be passed to a set of LLM prompts designed to extract the various elements of a graph index. Longer text chunks require fewer LLM calls for such extraction, but suffer from the recall degradation of longer LLM context windows (Kuratov et al., 2024; Liu et al., 2023). This behavior can be observed in Figure 2 in the case of a single extraction round (i.e., with zero gleanings): on a sample dataset (HotPotQA, Yang et al., 2018), using a chunk size of 600 token extracted almost twice as many entity references as when using a chunk size of 2400. While more references are generally better, any extraction process needs to balance recall and precision for the target activity.\n\n# 2.2 Text Chunks \u2192 Element Instances\n\nThe baseline requirement for this step is to identify and extract instances of graph nodes and edges from each chunk of source text. We do this using a multipart LLM prompt that first identifies all entities in the text, including their name, type, and description, before identifying all relationships between clearly-related entities, including the source and target entities and a description of their relationship. Both kinds of element instance are output in a single list of delimited tuples. The primary opportunity to tailor this prompt to the domain of the document corpus lies in the choice of few-shot examples provided to the LLM for in-context learning (Brown et al., 2020).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3424, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "fcf90fc9-af5b-4468-9202-3cc55a77b5eb", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4cd05d7-6566-4493-8c4b-a480942d2c2d", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "f0d060d62a0acaba9afe4f4a318589437383f4bdb7b5dc33a054e2ac106f7c19", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, while our default prompt extracting the broad class of \u201cnamed entities\u201d like people, places, and organizations is generally applicable, domains with specialized knowledge (e.g., science, medicine, law) will benefit from few-shot examples specialized to those domains. We also support a secondary extraction prompt for any additional covariates we would like to associate with the extracted node instances. Our default covariate prompt aims to extract claims linked to detected entities, including the subject, object, type, description, source text span, and start and end dates. To balance the needs of efficiency and quality, we use multiple rounds of \u201cgleanings\u201d, up to a specified maximum, to encourage the LLM to detect any additional entities it may have missed on prior extraction rounds. This is a multi-stage process in which we first ask the LLM to assess whether all entities were extracted, using a logit bias of 100 to force a yes/no decision. If the LLM responds that entities were missed, then a continuation indicating that \u201cMANY entities were missed in the last extraction\u201d encourages the LLM to glean these missing entities. This approach allows us to use larger chunk sizes without a drop in quality (Figure 2) or the forced introduction of noise.\n\n# 2.3 Element Instances \u2192 Element Summaries\n\nThe use of an LLM to \u201cextract\u201d descriptions of entities, relationships, and claims represented in source texts is already a form of abstractive summarization, relying on the LLM to create independently meaningful summaries of concepts that may be implied but not stated by the text itself (e.g., the presence of implied relationships). To convert all such instance-level summaries into single blocks of descriptive text for each graph element (i.e., entity node, relationship edge, and claim covariate) requires a further round of LLM summarization over matching groups of instances. A potential concern at this stage is that the LLM may not consistently extract references to the same entity in the same text format, resulting in duplicate entity elements and thus duplicate nodes in the entity graph. However, since all closely-related \u201ccommunities\u201d of entities will be detected and summarized in the following step, and given that LLMs can understand the common entity behind multiple name variations, our overall approach is resilient to such variations provided there is sufficient connectivity from all variations to a shared set of closely-related entities. Overall, our use of rich descriptive text for homogeneous nodes in a potentially noisy graph structure is aligned with both the capabilities of LLMs and the needs of global, query-focused summarization. These qualities also differentiate our graph index from typical knowledge graphs, which rely on concise and consistent knowledge triples (subject, predicate, object) for downstream reasoning tasks.\n\n# 2.4 Element Summaries \u2192 Graph Communities\n\nThe index created in the previous step can be modelled as an homogeneous undirected weighted graph in which entity nodes are connected by relationship edges, with edge weights representing the normalized counts of detected relationship instances. Given such a graph, a variety of community detection algorithms may be used to partition the graph into communities of nodes with stronger connections to one another than to the other nodes in the graph (e.g., see the surveys by Fortunato, 2010 and Jin et al., 2021). In our pipeline, we use Leiden (Traag et al., 2019) on account of its ability to recover hierarchical community structure of large-scale graphs efficiently (Figure 3). Each level of this hierarchy provides a community partition that covers the nodes of the graph in a mutually-exclusive, collective-exhaustive way, enabling divide-and-conquer global summarization.\n\n# 2.5 Graph Communities \u2192 Community Summaries\n\nThe next step is to create report-like summaries of each community in the Leiden hierarchy, using a method designed to scale to very large datasets. These summaries are independently useful in their own right as a way to understand the global structure and semantics of the dataset, and may themselves be used to make sense of a corpus in the absence of a question. For example, a user may scan through community summaries at one level looking for general themes of interest, then follow links to the reports at the lower level that provide more details for each of the subtopics. Here, however, we focus on their utility as part of a graph-based index used for answering global queries. Community summaries are generated in the following way:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4609, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "1381d50a-9672-41b5-a22c-449efc28e89a", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cceb9a1-b140-4bbc-ad5e-20f4323a0107", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "ac9f881517d4c766c291129ba7e606d490f13d2d7e8491e254aab5fbd88b647e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Figure 3: Graph communities detected using the Leiden algorithm (Traag et al., 2019) over the MultiHop-RAG (Tang and Yang, 2024) dataset as indexed.\n\nCircles represent entity nodes with size proportional to their degree. Node layout was performed via OpenORD (Martin et al., 2011) and Force Atlas 2 (Jacomy et al., 2014). Node colors represent entity communities, shown at two levels of hierarchical clustering: (a) Level 0, corresponding to the hierarchical partition with maximum modularity, and (b) Level 1, which reveals internal structure within these root-level communities.\n\n# \u2022 Leaf-level communities.\n\nThe element summaries of a leaf-level community (nodes, edges, covariates) are prioritized and then iteratively added to the LLM context window until the token limit is reached. The prioritization is as follows: for each community edge in decreasing order of combined source and target node degree (i.e., overall prominence), add descriptions of the source node, target node, linked covariates, and the edge itself.\n\n# \u2022 Higher-level communities.\n\nIf all element summaries fit within the token limit of the context window, proceed as for leaf-level communities and summarize all element summaries within the community. Otherwise, rank sub-communities in decreasing order of element summary tokens and iteratively substitute sub-community summaries (shorter) for their associated element summaries (longer) until fit within the context window is achieved.\n\n# 2.6 Community Summaries \u2192 Community Answers \u2192 Global Answer\n\nGiven a user query, the community summaries generated in the previous step can be used to generate a final answer in a multi-stage process. The hierarchical nature of the community structure also means that questions can be answered using the community summaries from different levels, raising the question of whether a particular level in the hierarchical community structure offers the best balance of summary detail and scope for general sensemaking questions (evaluated in section 3).\n\nFor a given community level, the global answer to any user query is generated as follows:\n\n# \u2022 Prepare community summaries.\n\nCommunity summaries are randomly shuffled and divided into chunks of pre-specified token size. This ensures relevant information is distributed across chunks, rather than concentrated (and potentially lost) in a single context window.\n\n# \u2022 Map community answers.\n\nGenerate intermediate answers in parallel, one for each chunk. The LLM is also asked to generate a score between 0-100 indicating how helpful the generated answer is in answering the target question. Answers with score 0 are filtered out.\n\n# \u2022 Reduce to global answer.\n\nIntermediate community answers are sorted in descending order of helpfulness score and iteratively added into a new context window until the token limit is reached. This final context is used to generate the global answer returned to the user.\n\n5", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2927, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "7ee2e4ff-4f0e-4ba1-a84a-3cf5119499cb", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e1f2ac7-be0e-4ed6-a484-d1ad150300d5", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "03de13e4bf63ab5f16e12a89dd88f40e20cc3ddbdb9dc675b80a93fd4f7782e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Dataset\n\nExample activity framing and generation of global sensemaking questions\n\n# Podcast\n\nUser: A tech journalist looking for insights and trends in the tech industry\n\nTask: Understanding how tech leaders view the role of policy and regulation\n\n# Questions:\n\n1. Which episodes deal primarily with tech policy and government regulation?\n2. How do guests perceive the impact of privacy laws on technology development?\n3. Do any guests discuss the balance between innovation and ethical considerations?\n4. What are the suggested changes to current policies mentioned by the guests?\n5. Are collaborations between tech companies and governments discussed and how?\n\n# News\n\nUser: Educator incorporating current affairs into curricula\n\nTask: Teaching about health and wellness\n\n# Questions:\n\n1. What current topics in health can be integrated into health education curricula?\n2. How do news articles address the concepts of preventive medicine and wellness?\n3. Are there examples of health articles that contradict each other, and if so, why?\n4. What insights can be gleaned about public health priorities based on news coverage?\n5. How can educators use the dataset to highlight the importance of health literacy?\n\n# Table 1:\n\nExamples of potential users, tasks, and questions generated by the LLM based on short descriptions of the target datasets. Questions target global understanding rather than specific details.\n\n# Evaluation\n\n# 3.1 Datasets\n\nWe selected two datasets in the one million token range, each equivalent to about 10 novels of text and representative of the kind of corpora that users may encounter in their real world activities:\n\n- Podcast transcripts. Compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders (Behind the Tech, Scott, 2024). Size: 1669 \u00d7 600-token text chunks, with 100-token overlaps between chunks (\u223c1 million tokens).\n- News articles. Benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and science (MultiHop-RAG; Tang and Yang, 2024). Size: 3197 \u00d7 600-token text chunks, with 100-token overlaps between chunks (\u223c1.7 million tokens).\n\n# 3.2 Queries\n\nMany benchmark datasets for open-domain question answering exist, including HotPotQA (Yang et al., 2018), MultiHop-RAG (Tang and Yang, 2024), and MT-Bench (Zheng et al., 2024). However, the associated question sets target explicit fact retrieval rather than summarization for the purpose of data sensemaking, i.e., the process though which people inspect, engage with, and contextualize data within the broader scope of real-world activities (Koesten et al., 2021). Similarly, methods for extracting latent summarization queries from source texts also exist (Xu and Lapata, 2021), but such extracted questions can target details that betray prior knowledge of the texts.\n\nTo evaluate the effectiveness of RAG systems for more global sensemaking tasks, we need questions that convey only a high-level understanding of dataset contents, and not the details of specific texts. We used an activity-centered approach to automate the generation of such questions: given a short description of a dataset, we asked the LLM to identify N potential users and N tasks per user, then for each (user, task) combination, we asked the LLM to generate N questions that require understanding of the entire corpus. For our evaluation, a value of N = 5 resulted in 125 test questions per dataset. Table 1 shows example questions for each of the two evaluation datasets.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "40262df2-ed20-471a-b375-e3a1e2f4cd42", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b6a62eab-6554-4801-b553-b404426322d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "53d7ebb2b814bf4fe0c445af27b252fa7000124aeff34619796ffe6c12b4ed15", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# 3.3 Conditions\n\nWe compare six different conditions in our analysis, including Graph RAG using four levels of graph communities (C0, C1, C2, C3), a text summarization method applying our map-reduce approach directly to source texts (TS), and a na\u00efve \u201csemantic search\u201d RAG approach (SS):\n\n- CO. Uses root-level community summaries (fewest in number) to answer user queries.\n- C1. Uses high-level community summaries to answer queries. These are sub-communities of C0, if present, otherwise C0 communities projected down.\n- C2. Uses intermediate-level community summaries to answer queries. These are sub-communities of C1, if present, otherwise C1 communities projected down.\n- C3. Uses low-level community summaries (greatest in number) to answer queries. These are sub-communities of C2, if present, otherwise C2 communities projected down.\n- TS. The same method as in subsection 2.6, except source texts (rather than community summaries) are shuffled and chunked for the map-reduce summarization stages.\n- SS. An implementation of na\u00efve RAG in which text chunks are retrieved and added to the available context window until the specified token limit is reached.\n\nThe size of the context window and the prompts used for answer generation are the same across all six conditions (except for minor modifications to reference styles to match the types of context information used). Conditions only differ in how the contents of the context window are created.\n\nThe graph index supporting conditions C0-C3 was created using our generic prompts for entity and relationship extraction only, with entity types and few-shot examples tailored to the domain of the data. The graph indexing process used a context window size of 600 tokens with 1 gleaning for the Podcast dataset and 0 gleanings for the News dataset.\n\n# 3.4 Metrics\n\nLLMs have been shown to be good evaluators of natural language generation, achieving state-of-the-art or competitive results compared against human judgements (Wang et al., 2023a; Zheng et al., 2024). While this approach can generate reference-based metrics when gold standard answers are known, it is also capable of measuring the qualities of generated texts (e.g., fluency) in a reference-free style (Wang et al., 2023a) as well as in head-to-head comparison of competing outputs (LLM-as-a-judge, Zheng et al., 2024). LLMs have also shown promise at evaluating the performance of conventional RAG systems, automatically evaluating qualities like context relevance, faithfulness, and answer relevance (RAGAS, Es et al., 2023).\n\nGiven the multi-stage nature of our Graph RAG mechanism, the multiple conditions we wanted to compare, and the lack of gold standard answers to our activity-based sensemaking questions, we decided to adopt a head-to-head comparison approach using an LLM evaluator. We selected three target metrics capturing qualities that are desirable for sensemaking activities, as well as a control metric (directness) used as an indicator of validity. Since directness is effectively in opposition to comprehensiveness and diversity, we would not expect any method to win across all four metrics.\n\nOur head-to-head measures computed using an LLM evaluator are as follows:\n\n- Comprehensiveness. How much detail does the answer provide to cover all aspects and details of the question?\n- Diversity. How varied and rich is the answer in providing different perspectives and insights on the question?\n- Empowerment. How well does the answer help the reader understand and make informed judgements about the topic?\n- Directness. How specifically and clearly does the answer address the question?\n\nFor our evaluation, the LLM is provided with the question, target metric, and a pair of answers, and asked to assess which answer is better according to the metric, as well as why. It returns the winner if one exists, otherwise a tie if they are fundamentally similar and the differences are negligible. To account for the stochasticity of LLMs, we run each comparison five times and use mean scores. Table 2 shows an example of LLM-generated assessment.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4089, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "e149a73c-d513-4ce8-9cd2-329b55fe389f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f5085ed6-51f5-42b5-b3f9-dc86c09b5f72", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "f5cfdb831ff2a7c26ba9124d2b9676cbd5cd6956da9b19fda1ec07ee3e2d3411", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Overview of Prominent Public Figures in Entertainment\n\nThe entertainment industry is vast and diverse, encompassing film, television, music, sports, and digital media. Certain public figures stand out due to their significant contributions and influence across these sectors. The following summary highlights key individuals who are repeatedly mentioned in various entertainment articles, reflecting their impact and presence within the industry.\n\n- Actors and Directors\n- Public Figures in Controversy\n- Musicians and Executives\n- Athletes and Coaches\n- Influencers and Entrepreneurs\n\nThe repeated mention of these figures in entertainment articles signifies their ongoing relevance and the public\u2019s interest in their work. Their influence spans across various aspects of entertainment, from shaping cultural narratives in film and television to driving trends in music and digital media. These individuals not only contribute to their respective fields but also influence the broader cultural landscape, often becoming central figures in social discussions and public discourse.\n\n# Public Figures Mentioned\n\nPublic figures who are repeatedly mentioned across various entertainment articles include Taylor Swift, Travis Kelce, Britney Spears, and Justin Timberlake. These individuals have been highlighted for various reasons, ranging from their professional achievements to their personal lives.\n\nTaylor Swift [...] Travis Kelce [...] Britney Spears [...] Justin Timberlake [...]\n\nThese figures are frequently covered due to their high-profile status and the public\u2019s interest in their careers and personal lives. Their activities, whether in music, sports, or personal relationships, have significant cultural and economic impacts, as evidenced by the media coverage and public reactions.\n\n# Comparative Analysis\n\n# Comprehensiveness\n\nWinner=1 (Graph RAG)\n\nAnswer 1 is better because it provides a more comprehensive and detailed list of public figures from a wider range of entertainment sectors, including film, television, music, sports, gaming, and digital media. It also includes specific examples of their contributions and the impact they have on their respective fields, as well as mentions of controversies and their implications. Answer 2, while detailed in its coverage of a few individuals, is limited to a smaller number of public figures and focuses primarily on their personal lives and relationships rather than a broad spectrum of their professional influence across the entertainment industry.\n\n# Diversity\n\nWinner=1 (Graph RAG)\n\nAnswer 1 is better because it provides a more varied and rich response by covering a wide range of public figures from different sectors of the entertainment industry, including film, television, music, sports, gaming, and digital media. It offers insights into the contributions and influence of these figures, as well as controversies and their impact on public discourse. The answer also cites specific data sources for each mentioned figure, indicating a diverse range of evidence to support the claims. In contrast, Answer 2 focuses on a smaller group of public figures, primarily from the music industry and sports, and relies heavily on a single source for data, which makes it less diverse in perspectives and insights.\n\n# Empowerment\n\nWinner=1 (Graph RAG)\n\nAnswer 1 is better because it provides a comprehensive and structured overview of public figures across various sectors of the entertainment industry, including film, television, music, sports, and digital media. It lists multiple individuals, providing specific examples of their contributions and the context in which they are mentioned in entertainment articles, along with references to data reports for each claim. This approach helps the reader understand the breadth of the topic and make informed judgments without being misled. In contrast, Answer 2 focuses on a smaller group of public figures and primarily discusses their personal lives and relationships, which may not provide as broad an understanding of the topic. While Answer 2 also cites sources, it does not match the depth and variety of Answer 1.\n\n# Directness\n\nWinner=2 (Na\u00efve RAG)\n\nAnswer 2 is better because it directly lists specific public figures who are repeatedly mentioned across various entertainment articles, such as Taylor Swift, Travis Kelce, Britney Spears, and Justin Timberlake, and provides concise explanations for their frequent mentions. Answer 1, while comprehensive, includes a lot of detailed information about various figures in different sectors of entertainment, which, while informative, does not directly answer the question with the same level of conciseness and specificity as Answer 2.\n\n# Example Question for the News Article Dataset\n\nTable 2: Example question for the News article dataset, with generated answers from Graph RAG (C2) and Na\u00efve RAG, as well as LLM-generated assessments.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4909, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "cca54c95-f512-4626-af9b-87b57e2c759f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed1f6401-4b2b-4d20-a2e9-5bce80a45674", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "9860d87b59c78feec9c73c8b759c96787e0ca423f858756096aa0fc3ba131de6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Podcast transcripts\n\n|SS|TS|C0|C1|C2|C3|\n|---|---|---|---|---|---|\n|50|83|72|75|78|79|\n|17|50|50|52|57|56|\n|28|50|50|47|50|51|\n|25|48|53|50|48|50|\n|22|43|50|52|50|48|\n|21|44|49|50|52|50|\n\n# Comprehensiveness\n\n# Diversity\n\n# Empowerment\n\n# Directness\n\n|SS|TS|C0|C1|C2|C3|\n|---|---|---|---|---|---|\n|50|80|72|75|79|79|\n|20|50|56|59|62|64|\n|28|44|50|48|46|48|\n|25|41|52|50|42|45|\n|21|38|54|58|50|41|\n|21|36|52|55|59|50|\n\nFigure 4: Head-to-head win rate percentages of (row condition) over (column condition) across two datasets, four metrics, and 125 questions per comparison (each repeated five times and averaged). The overall winner per dataset and metric is shown in bold. Self-win rates were not computed but are shown as the expected 50% for reference. All Graph RAG conditions outperformed na\u00efve RAG on comprehensiveness and diversity. Conditions C1-C3 also showed slight improvements in answer comprehensiveness and diversity over TS (global text summarization without a graph index).\n\n# 3.5 Configuration\n\nThe effect of context window size on any particular task is unclear, especially for models like gpt-4-turbo with a large context size of 128k tokens. Given the potential for information to be \u201clost in the middle\u201d of longer contexts (Kuratov et al., 2024; Liu et al., 2023), we wanted to explore the effects of varying the context window size for our combinations of datasets, questions, and metrics. In particular, our goal was to determine the optimum context size for our baseline condition (SS) and then use this uniformly for all query-time LLM use. To that end, we tested four context window sizes: 8k, 16k, 32k and 64k. Surprisingly, the smallest context window size tested (8k) was universally better for all comparisons on comprehensiveness (average win rate of 58.1%), while performing comparably with larger context sizes on diversity (average win rate = 52.4%), and empowerment (average win rate = 51.3%). Given our preference for more comprehensive and diverse answers, we therefore used a fixed context window size of 8k tokens for the final evaluation.\n\n# 3.6 Results\n\nThe indexing process resulted in a graph consisting of 8564 nodes and 20691 edges for the Podcast dataset, and a larger graph of 15754 nodes and 19520 edges for the News dataset. Table 3 shows the number of community summaries at different levels of each graph community hierarchy.\n\nGlobal approaches vs. na\u00efve RAG. As shown in Figure 4, global approaches consistently outperformed the na\u00efve RAG (SS) approach in both comprehensiveness and diversity metrics across datasets. Specifically, global approaches achieved comprehensiveness win rates between 72-83% for Podcast transcripts and 72-80% for News articles, while diversity win rates ranged from 75-82% and 62-71% respectively. Our use of directness as a validity test also achieved the expected results, i.e., that na\u00efve RAG produces the most direct responses across all comparisons.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "506f756e-4371-4326-abb0-35816c7b966c", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec745805-b431-48b4-b82c-6107243d2d58", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e6b7d9fb1ef245bcbb4a510303f39719d87793fce80dcf3cd96102a63874ae4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "068c13ee-e8b8-43ef-ac8e-c515d07ef1d4", "node_type": "1", "metadata": {}, "hash": "7fc6de3f293b14cc332203d259657abd99adfb01c2ae0dd5487912ace031c875", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Podcast Transcripts\n\n# News Articles\n\n|Units|C0|C1|C2|C3|TS| | | | | |\n|---|---|---|---|---|---|---|---|---|---|---|\n| |34|367|969|1310|1669| | | | | |\n|Tokens|26657|225756|565720|746100|1014611| | | | | |\n|% Max|2.6|22.2|55.8|73.5|100| | | | | |\n\nTable 3: Number of context units (community summaries for C0-C3 and text chunks for TS), corresponding token counts, and percentage of the maximum token count. Map-reduce summarization of source texts is the most resource-intensive approach requiring the highest number of context tokens. Root-level community summaries (C0) require dramatically fewer tokens per query (9x-43x).\n\nCommunity summaries vs. source texts. When comparing community summaries to source texts using Graph RAG, community summaries generally provided a small but consistent improvement in answer comprehensiveness and diversity, except for root-level summaries. Intermediate-level summaries in the Podcast dataset and low-level community summaries in the News dataset achieved comprehensiveness win rates of 57% and 64%, respectively. Diversity win rates were 57% for Podcast intermediate-level summaries and 60% for News low-level community summaries. Table 3 also illustrates the scalability advantages of Graph RAG compared to source text summarization: for low-level community summaries (C3), Graph RAG required 26-33% fewer context tokens, while for root-level community summaries (C0), it required over 97% fewer tokens. For a modest drop in performance compared with other global methods, root-level Graph RAG offers a highly efficient method for the iterative question answering that characterizes sensemaking activity, while retaining advantages in comprehensiveness (72% win rate) and diversity (62% win rate) over na\u00efve RAG.\n\nEmpowerment. Empowerment comparisons showed mixed results for both global approaches versus na\u00efve RAG (SS) and Graph RAG approaches versus source text summarization (TS). Ad-hoc LLM use to analyze LLM reasoning for this measure indicated that the ability to provide specific examples, quotes, and citations was judged to be key to helping users reach an informed understanding. Tuning element extraction prompts may help to retain more of these details in the Graph RAG index.\n\n# 4 Related Work\n\n# 4.1 RAG Approaches and Systems\n\nWhen using LLMs, RAG involves first retrieving relevant information from external data sources, then adding this information to the context window of the LLM along with the original query (Ram et al., 2023). Na\u00efve RAG approaches (Gao et al., 2023) do this by converting documents to text, splitting text into chunks, and embedding these chunks into a vector space in which similar positions represent similar semantics. Queries are then embedded into the same vector space, with the text chunks of the nearest k vectors used as context. More advanced variations exist, but all solve the problem of what to do when an external dataset of interest exceeds the LLM\u2019s context window.\n\nAdvanced RAG systems include pre-retrieval, retrieval, post-retrieval strategies designed to overcome the drawbacks of Na\u00efve RAG, while Modular RAG systems include patterns for iterative and dynamic cycles of interleaved retrieval and generation (Gao et al., 2023). Our implementation of Graph RAG incorporates multiple concepts related to other systems. For example, our community summaries are a kind of self-memory (Selfmem, Cheng et al., 2024) for generation-augmented retrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation of community answers from these summaries is a kind of iterative (Iter-RetGen, Shao et al., 2023) or federated (FeB4RAG, Wang et al., 2024) retrieval-generation strategy. Other systems have also combined these concepts for multi-document summarization (CAiRE-COVID, Su et al., 2020) and multi-hop question answering (ITRG, Feng et al., 2023; IR-CoT, Trivedi et al., 2022; DSP, Khattab et al., 2022).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3951, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "068c13ee-e8b8-43ef-ac8e-c515d07ef1d4", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec745805-b431-48b4-b82c-6107243d2d58", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e6b7d9fb1ef245bcbb4a510303f39719d87793fce80dcf3cd96102a63874ae4c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "506f756e-4371-4326-abb0-35816c7b966c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "648d307ae672e34a712e5de4429768d283fa8f2405fdb3cd1d19ace89e259d93", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Our use of a hierarchical index and summarization also bears resemblance to further approaches, such as generating a hierarchical index of text chunks by clustering the vectors of text embeddings (RAPTOR, Sarthi et al., 2024) or generating a \u201ctree of clarifications\u201d to answer multiple interpretations of ambiguous questions (Kim et al., 2023). However, none of these iterative or hierarchical approaches use the kind of self-generated graph index that enables Graph RAG.", "mimetype": "text/plain", "start_char_idx": 3952, "end_char_idx": 4423, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "738095aa-f979-4836-9819-d21592789eba", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a486463-97aa-46b1-a190-cfc56fac532e", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e1ad53ef9879cb94e58810412154c2d54d5c56d1dc74ab5a193ddf72c56a7abf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# 4.2 Graphs and LLMs\n\nUse of graphs in connection with LLMs and RAG is a developing research area, with multiple directions already established. These include using LLMs for knowledge graph creation (Trajanoska et al., 2023) and completion (Yao et al., 2023), as well as for the extraction of causal graphs (Ban et al., 2023; Zhang et al., 2024) from source texts. They also include forms of advanced RAG (Gao et al., 2023) where the index is a knowledge graph (KAPING, Baek et al., 2023), where subsets of the graph structure (G-Retriever, He et al., 2024) or derived graph metrics (Graph-ToolFormer, Zhang, 2023) are the objects of enquiry, where narrative outputs are strongly grounded in the facts of retrieved subgraphs (SURGE, Kang et al., 2023), where retrieved event-plot subgraphs are serialized using narrative templates (FABULA, Ranade and Joshi, 2023), and where the system supports both creation and traversal of text-relationship graphs for multi-hop question answering (Wang et al., 2023b). In terms of open-source software, a variety of graph databases are supported by both the LangChain (LangChain, 2024) and LlamaIndex (LlamaIndex, 2024) libraries, while a more general class of graph-based RAG applications is also emerging, including systems that can create and reason over knowledge graphs in both Neo4J (NaLLM, Neo4J, 2024) and NebulaGraph (GraphRAG, NebulaGraph, 2024) formats. Unlike our Graph RAG approach, however, none of these systems use the natural modularity of graphs to partition data for global summarization.\n\n# 5 Discussion\n\nLimitations of evaluation approach. Our evaluation to date has only examined a certain class of sensemaking questions for two corpora in the region of 1 million tokens. More work is needed to understand how performance varies across different ranges of question types, data types, and dataset sizes, as well as to validate our sensemaking questions and target metrics with end users. Comparison of fabrication rates, e.g., using approaches like SelfCheckGPT (Manakul et al., 2023), would also improve on the current analysis.\n\nTrade-offs of building a graph index. We consistently observed Graph RAG achieve the best head-to-head results against other methods, but in many cases the graph-free approach to global summarization of source texts performed competitively. The real-world decision about whether to invest in building a graph index depends on multiple factors, including the compute budget, expected number of lifetime queries per dataset, and value obtained from other aspects of the graph index (including the generic community summaries and the use of other graph-related RAG approaches).\n\nFuture work. The graph index, rich text annotations, and hierarchical community structure supporting the current Graph RAG approach offer many possibilities for refinement and adaptation. This includes RAG approaches that operate in a more local manner, via embedding-based matching of user queries and graph annotations, as well as the possibility of hybrid RAG schemes that combine embedding-based matching against community reports before employing our map-reduce summarization mechanisms. This \u201croll-up\u201d operation could also be extended across more levels of the community hierarchy, as well as implemented as a more exploratory \u201cdrill down\u201d mechanism that follows the information scent contained in higher-level community summaries.\n\n# 6 Conclusion\n\nWe have presented a global approach to Graph RAG, combining knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human sensemaking over entire text corpora. Initial evaluations show substantial improvements over a na\u00efve RAG baseline for both the comprehensiveness and diversity of answers, as well as favorable comparisons to a global but graph-free approach using map-reduce source text summarization. For situations requiring many global queries over the same dataset, summaries of root-level communities in the entity-based graph index provide a data index that is both superior to na\u00efve RAG and achieves competitive performance to other global methods at a fraction of the token cost. An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4304, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "12fcb2d1-091e-472e-bfef-bec41ae99002", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b0ab76-1bc2-456b-84e0-e21eafb8667a", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "d40f5e08ccc0385a89d486d7fd64a36268ecfe3f99ff36816c2800ac232f9a0d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77a83051-73b5-4bde-a106-60b8b6b9668f", "node_type": "1", "metadata": {}, "hash": "3a7d68e0f78278d3511fc5b17e8d1d9f8778234c525f5fa4c416585d825a318f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Acknowledgements\n\nWe would also like to thank the following people who contributed to the work: Alonso Guevara Fern\u00e1ndez, Amber Hoak, Andr\u00e9s Morales Esquivel, Ben Cutler, Billie Rinaldi, Chris Sanchez, Chris Trevino, Christine Caggiano, David Tittsworth, Dayenne de Souza, Douglas Orbaker, Ed Clark, Gabriel Nieves-Ponce, Gaudy Blanco Meneses, Kate Lytvynets, Katy Smith, M\u00f3nica Carvajal, Nathan Evans, Richard Ortega, Rodrigo Racanicci, Sarah Smith, and Shane Solomon.\n\n# References\n\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. (2023). Gpt-4 technical report. arXiv preprint arXiv:2303.08774.\n\nAnil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., et al. (2023). Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805.\n\nBaek, J., Aji, A. F., and Saffari, A. (2023). Knowledge-augmented language model prompting for zero-shot knowledge graph question answering. arXiv preprint arXiv:2306.04136.\n\nBan, T., Chen, L., Wang, X., and Chen, H. (2023). From query tools to causal architects: Harnessing large language models for advanced causal discovery from data.\n\nBaumel, T., Eyal, M., and Elhadad, M. (2018). Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models. arXiv preprint arXiv:1801.07704.\n\nBlondel, V. D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of communities in large networks. Journal of statistical mechanics: theory and experiment, 2008(10):P10008.\n\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901.\n\nCheng, X., Luo, D., Chen, X., Liu, L., Zhao, D., and Yan, R. (2024). Lift yourself up: Retrieval-augmented text generation with self-memory. Advances in Neural Information Processing Systems, 36.\n\nDang, H. T. (2006). Duc 2005: Evaluation of question-focused summarization systems. In Proceedings of the Workshop on Task-Focused Summarization and Question Answering, pages 48\u201355.\n\nEs, S., James, J., Espinosa-Anke, L., and Schockaert, S. (2023). Ragas: Automated evaluation of retrieval augmented generation. arXiv preprint arXiv:2309.15217.\n\nFeng, Z., Feng, X., Zhao, D., Yang, M., and Qin, B. (2023). Retrieval-generation synergy augmented large language models. arXiv preprint arXiv:2310.05149.\n\nFortunato, S. (2010). Community detection in graphs. Physics reports, 486(3-5):75\u2013174.\n\nGao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., and Wang, H. (2023). Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997.\n\nGoodwin, T. R., Savery, M. E., and Demner-Fushman, D. (2020). Flight of the pegasus?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2978, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "77a83051-73b5-4bde-a106-60b8b6b9668f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b0ab76-1bc2-456b-84e0-e21eafb8667a", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "d40f5e08ccc0385a89d486d7fd64a36268ecfe3f99ff36816c2800ac232f9a0d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "12fcb2d1-091e-472e-bfef-bec41ae99002", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "0fe02d611577c594359b49ff9ea7da0ec3495bd1658aed01a8ba94f61bcb44e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(2020). Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization. In Proceedings of COLING. International Conference on Computational Linguistics, volume 2020, page 5640. NIH Public Access.\n\nHe, X., Tian, Y., Sun, Y., Chawla, N. V., Laurent, T., LeCun, Y., Bresson, X., and Hooi, B. (2024). G-retriever: Retrieval-augmented generation for textual graph understanding and question answering. arXiv preprint arXiv:2402.07630.", "mimetype": "text/plain", "start_char_idx": 2948, "end_char_idx": 3427, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "cc76f242-a34c-42e5-8af1-7297c8acc192", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6af52b0c-3a72-42e6-89f2-07b81abf16e1", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "3a235a4cc02e7cf4e41db1b376b4cda3e2520b617de0f5d61d5bcba9eba7c65b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d8290ca-d8a9-4101-b6a5-36c46e2698b3", "node_type": "1", "metadata": {}, "hash": "7ec39575dd9d00178090a1c51bacd0cc0f100e0f0c57dcab9f95e8c48bf04332", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# References\n\nJacomy, M., Venturini, T., Heymann, S., and Bastian, M. (2014). Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software. PLoS ONE 9(6): e98679. https://doi.org/10.1371/journal.pone.0098679.\n\nJin, D., Yu, Z., Jiao, P., Pan, S., He, D., Wu, J., Philip, S. Y., and Zhang, W. (2021). A survey of community detection approaches: From statistical modeling to deep learning. IEEE Transactions on Knowledge and Data Engineering, 35(2):1149\u20131170.\n\nKang, M., Kwak, J. M., Baek, J., and Hwang, S. J. (2023). Knowledge graph-augmented language models for knowledge-grounded dialogue generation. arXiv preprint arXiv:2305.18846.\n\nKhattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. (2022). Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp. arXiv preprint arXiv:2212.14024.\n\nKim, G., Kim, S., Jeon, B., Park, J., and Kang, J. (2023). Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models. arXiv preprint arXiv:2310.14696.\n\nKlein, G., Moon, B., and Hoffman, R. R. (2006a). Making sense of sensemaking 1: Alternative perspectives. IEEE intelligent systems, 21(4):70\u201373.\n\nKlein, G., Moon, B., and Hoffman, R. R. (2006b). Making sense of sensemaking 2: A macrocognitive model. IEEE Intelligent systems, 21(5):88\u201392.\n\nKoesten, L., Gregory, K., Groth, P., and Simperl, E. (2021). Talking datasets\u2013understanding data sensemaking behaviours. International journal of human-computer studies, 146:102562.\n\nKuratov, Y., Bulatov, A., Anokhin, P., Sorokin, D., Sorokin, A., and Burtsev, M. (2024). In search of needles in a 11m haystack: Recurrent memory finds what llms miss.\n\nLangChain (2024). Langchain graphs. https://python.langchain.com/docs/use cases/graph/.\n\nLaskar, M. T. R., Hoque, E., and Huang, J. (2020). Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models. In Advances in Artificial Intelligence: 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020, Ottawa, ON, Canada, May 13\u201315, 2020, Proceedings 33, pages 342\u2013348. Springer.\n\nLaskar, M. T. R., Hoque, E., and Huang, J. X. (2022). Domain adaptation with pre-trained transformers for query-focused abstractive text summarization. Computational Linguistics, 48(2):279\u2013320.\n\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K\u00fcttler, H., Lewis, M., Yih, W.-t., Rocktaschel, T., et al. (2020). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459\u20139474.\n\nLiu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., and Liang, P. (2023). Lost in the middle: How language models use long contexts. arXiv:2307.03172.\n\nLiu, Y. and Lapata, M. (2019). Hierarchical transformers for multi-document summarization. arXiv preprint arXiv:1905.13164.\n\nLlamaIndex (2024). LlamaIndex Knowledge Graph Index.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3024, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "6d8290ca-d8a9-4101-b6a5-36c46e2698b3", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6af52b0c-3a72-42e6-89f2-07b81abf16e1", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "3a235a4cc02e7cf4e41db1b376b4cda3e2520b617de0f5d61d5bcba9eba7c65b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc76f242-a34c-42e5-8af1-7297c8acc192", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "a72af445eafd923f926c96422526a56786931cf14b52ea31943dc1e94898ae39", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "LlamaIndex (2024). LlamaIndex Knowledge Graph Index. https://docs.llamaindex.ai/en/stable/examples/index structs/knowledge graph/KnowledgeGraphDemo.html.\n\nManakul, P., Liusie, A., and Gales, M. J. (2023). Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. arXiv preprint arXiv:2303.08896.\n\nMao, Y., He, P., Liu, X., Shen, Y., Gao, J., Han, J., and Chen, W. (2020). Generation-augmented retrieval for open-domain question answering. arXiv preprint arXiv:2009.08553.\n\nMartin, S., Brown, W. M., Klavans, R., and Boyack, K. (2011). Openord: An open-source toolbox for large graph layout. SPIE Conference on Visualization and Data Analysis (VDA).\n\nMicrosoft (2023). The impact of large language models on scientific discovery: a preliminary study using gpt-4.", "mimetype": "text/plain", "start_char_idx": 2972, "end_char_idx": 3775, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "eb98d772-785b-43a8-a13b-40ec2036b3be", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfd503dd-865b-44fd-83a7-0895fb4cc3e7", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "b03e99c5e92862688bcda297d11c6ce05f8fe537448bbb4ddd89d777f475293f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "deeef575-0e6f-4604-a356-175f0b3de6d1", "node_type": "1", "metadata": {}, "hash": "763676edc73448e89b19b505821f4ef46046dbb64887a4dcf8137f9291d1a9a2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# References\n\nNebulaGraph (2024). Nebulagraph launches industry-first graph rag: Retrieval-augmented generation with llm based on knowledge graphs. https://www.nebula-graph.io/posts/graph-RAG.\n\nNeo4J (2024). Project NaLLM. https://github.com/neo4j/NaLLM.\n\nNewman, M. E. (2006). Modularity and community structure in networks. Proceedings of the national academy of sciences, 103(23):8577\u20138582.\n\nRam, O., Levine, Y., Dalmedigos, I., Muhlgay, D., Shashua, A., Leyton-Brown, K., and Shoham, Y. (2023). In-context retrieval-augmented language models. Transactions of the Association for Computational Linguistics, 11:1316\u20131331.\n\nRanade, P. and Joshi, A. (2023). Fabula: Intelligence report generation using retrieval-augmented narrative construction. arXiv preprint arXiv:2310.13848.\n\nSarthi, P., Abdullah, S., Tuli, A., Khanna, S., Goldie, A., and Manning, C. D. (2024). Raptor: Recursive abstractive processing for tree-organized retrieval. arXiv preprint arXiv:2401.18059.\n\nScott, K. (2024). Behind the Tech. https://www.microsoft.com/en-us/behind-the-tech.\n\nShao, Z., Gong, Y., Shen, Y., Huang, M., Duan, N., and Chen, W. (2023). Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy. arXiv preprint arXiv:2305.15294.\n\nSu, D., Xu, Y., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P. (2020). Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management. arXiv preprint arXiv:2005.03975.\n\nTang, Y. and Yang, Y. (2024). MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries. arXiv preprint arXiv:2401.15391.\n\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al. (2023). Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.\n\nTraag, V. A., Waltman, L., and Van Eck, N. J. (2019). From Louvain to Leiden: guaranteeing well-connected communities. Scientific Reports, 9(1).\n\nTrajanoska, M., Stojanov, R., and Trajanov, D. (2023). Enhancing knowledge graph construction using large language models. ArXiv, abs/2305.04676.\n\nTrivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A. (2022). Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint arXiv:2212.10509.\n\nWang, J., Liang, Y., Meng, F., Sun, Z., Shi, H., Li, Z., Xu, J., Qu, J., and Zhou, J. (2023a). Is chatgpt a good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048.\n\nWang, S., Khramtsova, E., Zhuang, S., and Zuccon, G. (2024). Feb4rag: Evaluating federated search in the context of retrieval augmented generation. arXiv preprint arXiv:2402.11891.\n\nWang, Y., Lipka, N., Rossi, R. A., Siu, A., Zhang, R., and Derr, T. (2023b). Knowledge graph prompting for multi-document question answering.\n\nXu, Y. and Lapata, M. (2021).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2917, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "deeef575-0e6f-4604-a356-175f0b3de6d1", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfd503dd-865b-44fd-83a7-0895fb4cc3e7", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "b03e99c5e92862688bcda297d11c6ce05f8fe537448bbb4ddd89d777f475293f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb98d772-785b-43a8-a13b-40ec2036b3be", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "a759037e95fa5cca94c55f8918240421d2acedd1aaa05ba2c017c74f07f13e34", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Xu, Y. and Lapata, M. (2021). Text summarization with latent queries. arXiv preprint arXiv:2106.00104.\n\nYang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W. W., Salakhutdinov, R., and Manning, C. D. (2018). HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\nYao, J.-g., Wan, X., and Xiao, J. (2017). Recent advances in document summarization. Knowledge and Information Systems, 53:297\u2013336.", "mimetype": "text/plain", "start_char_idx": 2888, "end_char_idx": 3375, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "768ab3bc-03e3-4545-928a-e0e2f13d9056", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68a01efd-b8fa-403c-ac0a-9f548ade6956", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "8ed714d99bbb0060e8422cf67e29353e0ccc875dda9cd5f403f06628698081ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# References\n\nYao, L., Peng, J., Mao, C., and Luo, Y. (2023). Exploring large language models for knowledge graph completion.\n\nZhang, J. (2023). Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt. arXiv preprint arXiv:2304.11116.\n\nZhang, Y., Zhang, Y., Gan, Y., Yao, L., and Wang, C. (2024). Causal graph discovery with retrieval-augmented generation based large language models. arXiv preprint arXiv:2402.15301.\n\nZheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et al. (2024). Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 687, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}]}, "54db79f0afc197a446b526a5a896b8edceb2903333814d8d8f88bc05eea1adaf": {"nodes": [{"__data__": {"id_": "a7d67b37-04a6-4dc9-bcd4-26d31fde6c44", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cc23039-683e-42ff-b4ba-404a92677b1d", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "9bae910b07e00ab8140e86243b92eb959c0240aadcc5c5c68c84722d31cb1c86", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " From Local to Global A Graph RAG Approach to QueryFocused SummarizationDarren Edge1 Ha Trinh1 Newman Cheng2 Joshua Bradley2 Alex Chao3arXiv240416130v1 csCL 24 Apr 2024 Apurva Mody3 Steven Truitt2 Jonathan Larson11Microsoft Research2Microsoft Strategic Missions and Technologies3Microsoft Office of the CTOdaedgetrinhhanewmanchengjoshbradleyachaomoapurvasteventruittjolarsomicrosoftcomThese authors contributed equally to this work AbstractThe use of retrievalaugmented generation RAG to retrieve relevant information from an external knowledge source enables large language models LLMs to answer questions over private andor previously unseen document collections However RAG fails on global questions directed at an entire text corpus such as What are the main themes in the dataset since this is inherently a queryfocused summarization QFS task rather than an explicit retrieval task Prior QFS methods meanwhile fail to scale to the quantities of text indexed by typical RAG systems To combine the strengths of these contrasting methods we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed Our approach uses an LLM to build a graphbased text index in two stages first to derive an entity knowledge graph from the source documents then to pregenerate community summaries for all groups of closelyrelated entities Given a question each community summary is used to generate a partial response before all partial responses are again summarized in a final response to the user For a class of global sensemaking questions over datasets in the 1 million token range we show that Graph RAG leads to substantial improvements over a nave RAG baseline for both the comprehensiveness and diversity of generated answers An opensource Pythonbased implementation of both global and local Graph RAG approaches is forthcoming at httpsakamsgraphrag 1 IntroductionHuman endeavors across a range of domains rely on our ability to read and reason about large collections of documents often reaching conclusions that go beyond anything stated in the source texts themselves With the emergence of large language models LLMs we are already witnessing attempts to automate humanlike sensemaking in complex domains like scientific discovery Microsoft 2023 and intelligence analysis Ranade and Joshi 2023 where sensemaking is defined asPreprint Under review", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2569, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "0722d552-97ea-4a86-bfad-9a3ed9bf8740", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "47a66a1a-6d36-4f9e-bafe-bcbc99e118ca", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "0d98989d455f942df670f85f81116f71a4d5aa2ab3c8b201201d85b4e4ad98f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Source Documents Global Answer text extraction and chunking Text Chunks domaintailored summarization Community Answers queryfocused summarization Community Summaries domaintailored summarization community detection Graph CommunitiesIndexing TimePipeline StageQuery TimeFigure 1 Graph RAG pipeline using an LLMderived graph index of source document text This index spans nodes eg entities edges eg relationships and covariates eg claims that have been detected extracted and summarized by LLM prompts tailored to the domain of the dataset Community detection eg Leiden Traag et al 2019 is used to partition the graph index into groups of elements nodes edges covariates that the LLM can summarize in parallel at both indexing time and query time The global answer to a given query is produced using a final round of queryfocused summarization over all community summaries reporting relevance to that querya motivated continuous effort to understand connections which can be among people places and events in order to anticipate their trajectories and act effectively Klein et al 2006a Supporting humanled sensemaking over entire text corpora however needs a way for people to both apply and refine their mental model of the data Klein et al 2006b by asking questions of a global nature Retrievalaugmented generation RAG Lewis et al 2020 is an established approach to answering user questions over entire datasets but it is designed for situations where these answers are contained locally within regions of text whose retrieval provides sufficient grounding for the generation taskInstead a more appropriate task framing is queryfocused summarization QFS Dang 2006 and in particular queryfocused abstractive summarization that generates natural language summaries and not just concatenated excerpts Baumel et al 2018 Laskar et al 2020 Yao et al 2017 In recent years however such distinctions between summarization tasks that are abstractive versus extractive generic versus queryfocused and singledocument versus multidocument have become less relevant While early applications of the transformer architecture showed substantial improvements on the stateoftheart for all such summarization tasks Goodwin et al 2020 Laskar et al 2022 Liu and Lapata 2019 these tasks are now trivialized by modern LLMs including the GPT Achiam et al 2023 Brown et al 2020 Llama Touvron et al 2023 and Gemini Anil et al 2023 series all of which can use incontext learning to summarize any content provided in their context windowThe challenge remains however for queryfocused abstractive summarization over an entire corpus Such volumes of text can greatly exceed the limits of LLM context windows and the expansion of such windows may not be enough given that information can be lost in the middle of longer contexts Kuratov et al 2024 Liu et al 2023 In addition although the direct retrieval of text chunks in nave RAG is likely inadequate for QFS tasks it is possible that an alternative form of preindexing could support a new RAG approach specifically targeting global summarizationIn this paper we present a Graph RAG approach based on global summarization of an LLMderived knowledge graph Figure 1 In contrast with related work that exploits the structured retrieval and traversal affordances of graph indexes subsection 42 we focus on a previously unexplored quality of graphs in this context their inherent modularity Newman 2006 and the ability of community detection algorithms to partition graphs into modular communities of closelyrelated nodes eg Louvain Blondel et al 2008 Leiden Traag et al 2019 LLMgenerated summaries of these", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3864, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "a7badba9-3d3b-4e72-a766-db7d7c8814f8", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "276af327-93a9-4532-aa29-c486b5f30cab", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "c2145fd838d089d74f0652df224e5f18629ac6d1fec1a2283cf9ca6f0b8cb76a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Entity references detected30000600 chunk size   200002400 chunk size   10000    00123Figure 2 How the entity references detected in the HotPotQA dataset Yang et al 2018 varies with chunk size and gleanings for our generic entity extraction prompt with gpt4turboCommunity descriptions provide complete coverage of the underlying graph index and the input documents it represents Queryfocused summarization of an entire corpus is then made possible using a mapreduce approach first using each community summary to answer the query independently and in parallel then summarizing all relevant partial answers into a final global answerTo evaluate this approach we used an LLM to generate a diverse set of activitycentered sensemaking questions from short descriptions of two representative realworld datasets containing podcast transcripts and news articles respectively For the target qualities of comprehensiveness diversity and empowerment defined in subsection 34 that develop understanding of broad issues and themes we both explore the impact of varying the hierarchical level of community summaries used to answer queries as well as compare to nave RAG and global mapreduce summarization of source texts We show that all global approaches outperform nave RAG on comprehensiveness and diversity and that Graph RAG with intermediate and lowlevel community summaries shows favorable performance over source text summarization on these same metrics at lower token costs 2 Graph RAG Approach  PipelineWe now unpack the highlevel data flow of the Graph RAG approach Figure 1 and pipeline describing key design parameters techniques and implementation details for each step 21 Source Documents  Text ChunksA fundamental design decision is the granularity with which input texts extracted from source documents should be split into text chunks for processing In the following step each of these chunks will be passed to a set of LLM prompts designed to extract the various elements of a graph index Longer text chunks require fewer LLM calls for such extraction but suffer from the recall degradation of longer LLM context windows Kuratov et al 2024 Liu et al 2023 This behavior can be observed in Figure 2 in the case of a single extraction round ie with zero gleanings on a sample dataset HotPotQA Yang et al 2018 using a chunk size of 600 token extracted almost twice as many entity references as when using a chunk size of 2400 While more references are generally better any extraction process needs to balance recall and precision for the target activity 22 Text Chunks  Element InstancesThe baseline requirement for this step is to identify and extract instances of graph nodes and edges from each chunk of source text We do this using a multipart LLM prompt that first identifies all entities in the text including their name type and description before identifying all relationships between clearlyrelated entities including the source and target entities and a description of their relationship Both kinds of element instance are output in a single list of delimited tuples The primary opportunity to tailor this prompt to the domain of the document corpus lies in the choice of fewshot examples provided to the LLM for incontext learning Brown et al 2020", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3424, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "fcf90fc9-af5b-4468-9202-3cc55a77b5eb", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4cd05d7-6566-4493-8c4b-a480942d2c2d", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "f0d060d62a0acaba9afe4f4a318589437383f4bdb7b5dc33a054e2ac106f7c19", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example while our default prompt extracting the broad class of named entities like people places and organizations is generally applicable domains with specialized knowledge eg science medicine law will benefit from fewshot examples specialized to those domains We also support a secondary extraction prompt for any additional covariates we would like to associate with the extracted node instances Our default covariate prompt aims to extract claims linked to detected entities including the subject object type description source text span and start and end dates To balance the needs of efficiency and quality we use multiple rounds of gleanings up to a specified maximum to encourage the LLM to detect any additional entities it may have missed on prior extraction rounds This is a multistage process in which we first ask the LLM to assess whether all entities were extracted using a logit bias of 100 to force a yesno decision If the LLM responds that entities were missed then a continuation indicating that MANY entities were missed in the last extraction encourages the LLM to glean these missing entities This approach allows us to use larger chunk sizes without a drop in quality Figure 2 or the forced introduction of noise 23 Element Instances  Element SummariesThe use of an LLM to extract descriptions of entities relationships and claims represented in source texts is already a form of abstractive summarization relying on the LLM to create independently meaningful summaries of concepts that may be implied but not stated by the text itself eg the presence of implied relationships To convert all such instancelevel summaries into single blocks of descriptive text for each graph element ie entity node relationship edge and claim covariate requires a further round of LLM summarization over matching groups of instances A potential concern at this stage is that the LLM may not consistently extract references to the same entity in the same text format resulting in duplicate entity elements and thus duplicate nodes in the entity graph However since all closelyrelated communities of entities will be detected and summarized in the following step and given that LLMs can understand the common entity behind multiple name variations our overall approach is resilient to such variations provided there is sufficient connectivity from all variations to a shared set of closelyrelated entities Overall our use of rich descriptive text for homogeneous nodes in a potentially noisy graph structure is aligned with both the capabilities of LLMs and the needs of global queryfocused summarization These qualities also differentiate our graph index from typical knowledge graphs which rely on concise and consistent knowledge triples subject predicate object for downstream reasoning tasks 24 Element Summaries  Graph CommunitiesThe index created in the previous step can be modelled as an homogeneous undirected weighted graph in which entity nodes are connected by relationship edges with edge weights representing the normalized counts of detected relationship instances Given such a graph a variety of community detection algorithms may be used to partition the graph into communities of nodes with stronger connections to one another than to the other nodes in the graph eg see the surveys by Fortunato 2010 and Jin et al 2021 In our pipeline we use Leiden Traag et al 2019 on account of its ability to recover hierarchical community structure of largescale graphs efficiently Figure 3 Each level of this hierarchy provides a community partition that covers the nodes of the graph in a mutuallyexclusive collectiveexhaustive way enabling divideandconquer global summarization 25 Graph Communities  Community SummariesThe next step is to create reportlike summaries of each community in the Leiden hierarchy using a method designed to scale to very large datasets These summaries are independently useful in their own right as a way to understand the global structure and semantics of the dataset and may themselves be used to make sense of a corpus in the absence of a question For example a user may scan through community summaries at one level looking for general themes of interest then follow links to the reports at the lower level that provide more details for each of the subtopics Here however we focus on their utility as part of a graphbased index used for answering global queries Community summaries are generated in the following way", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4609, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "1381d50a-9672-41b5-a22c-449efc28e89a", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cceb9a1-b140-4bbc-ad5e-20f4323a0107", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "ac9f881517d4c766c291129ba7e606d490f13d2d7e8491e254aab5fbd88b647e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Figure 3 Graph communities detected using the Leiden algorithm Traag et al 2019 over the MultiHopRAG Tang and Yang 2024 dataset as indexedCircles represent entity nodes with size proportional to their degree Node layout was performed via OpenORD Martin et al 2011 and Force Atlas 2 Jacomy et al 2014 Node colors represent entity communities shown at two levels of hierarchical clustering a Level 0 corresponding to the hierarchical partition with maximum modularity and b Level 1 which reveals internal structure within these rootlevel communities  Leaflevel communitiesThe element summaries of a leaflevel community nodes edges covariates are prioritized and then iteratively added to the LLM context window until the token limit is reached The prioritization is as follows for each community edge in decreasing order of combined source and target node degree ie overall prominence add descriptions of the source node target node linked covariates and the edge itself  Higherlevel communitiesIf all element summaries fit within the token limit of the context window proceed as for leaflevel communities and summarize all element summaries within the community Otherwise rank subcommunities in decreasing order of element summary tokens and iteratively substitute subcommunity summaries shorter for their associated element summaries longer until fit within the context window is achieved 26 Community Summaries  Community Answers  Global AnswerGiven a user query the community summaries generated in the previous step can be used to generate a final answer in a multistage process The hierarchical nature of the community structure also means that questions can be answered using the community summaries from different levels raising the question of whether a particular level in the hierarchical community structure offers the best balance of summary detail and scope for general sensemaking questions evaluated in section 3For a given community level the global answer to any user query is generated as follows  Prepare community summariesCommunity summaries are randomly shuffled and divided into chunks of prespecified token size This ensures relevant information is distributed across chunks rather than concentrated and potentially lost in a single context window  Map community answersGenerate intermediate answers in parallel one for each chunk The LLM is also asked to generate a score between 0100 indicating how helpful the generated answer is in answering the target question Answers with score 0 are filtered out  Reduce to global answerIntermediate community answers are sorted in descending order of helpfulness score and iteratively added into a new context window until the token limit is reached This final context is used to generate the global answer returned to the user5", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2927, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "7ee2e4ff-4f0e-4ba1-a84a-3cf5119499cb", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e1f2ac7-be0e-4ed6-a484-d1ad150300d5", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "03de13e4bf63ab5f16e12a89dd88f40e20cc3ddbdb9dc675b80a93fd4f7782e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " DatasetExample activity framing and generation of global sensemaking questions PodcastUser A tech journalist looking for insights and trends in the tech industryTask Understanding how tech leaders view the role of policy and regulation Questions1 Which episodes deal primarily with tech policy and government regulation2 How do guests perceive the impact of privacy laws on technology development3 Do any guests discuss the balance between innovation and ethical considerations4 What are the suggested changes to current policies mentioned by the guests5 Are collaborations between tech companies and governments discussed and how NewsUser Educator incorporating current affairs into curriculaTask Teaching about health and wellness Questions1 What current topics in health can be integrated into health education curricula2 How do news articles address the concepts of preventive medicine and wellness3 Are there examples of health articles that contradict each other and if so why4 What insights can be gleaned about public health priorities based on news coverage5 How can educators use the dataset to highlight the importance of health literacy Table 1Examples of potential users tasks and questions generated by the LLM based on short descriptions of the target datasets Questions target global understanding rather than specific details Evaluation 31 DatasetsWe selected two datasets in the one million token range each equivalent to about 10 novels of text and representative of the kind of corpora that users may encounter in their real world activities Podcast transcripts Compiled transcripts of podcast conversations between Kevin Scott Microsoft CTO and other technology leaders Behind the Tech Scott 2024 Size 1669  600token text chunks with 100token overlaps between chunks 1 million tokens News articles Benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories including entertainment business sports technology health and science MultiHopRAG Tang and Yang 2024 Size 3197  600token text chunks with 100token overlaps between chunks 17 million tokens 32 QueriesMany benchmark datasets for opendomain question answering exist including HotPotQA Yang et al 2018 MultiHopRAG Tang and Yang 2024 and MTBench Zheng et al 2024 However the associated question sets target explicit fact retrieval rather than summarization for the purpose of data sensemaking ie the process though which people inspect engage with and contextualize data within the broader scope of realworld activities Koesten et al 2021 Similarly methods for extracting latent summarization queries from source texts also exist Xu and Lapata 2021 but such extracted questions can target details that betray prior knowledge of the textsTo evaluate the effectiveness of RAG systems for more global sensemaking tasks we need questions that convey only a highlevel understanding of dataset contents and not the details of specific texts We used an activitycentered approach to automate the generation of such questions given a short description of a dataset we asked the LLM to identify N potential users and N tasks per user then for each user task combination we asked the LLM to generate N questions that require understanding of the entire corpus For our evaluation a value of N  5 resulted in 125 test questions per dataset Table 1 shows example questions for each of the two evaluation datasets", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "40262df2-ed20-471a-b375-e3a1e2f4cd42", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b6a62eab-6554-4801-b553-b404426322d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "53d7ebb2b814bf4fe0c445af27b252fa7000124aeff34619796ffe6c12b4ed15", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " 33 ConditionsWe compare six different conditions in our analysis including Graph RAG using four levels of graph communities C0 C1 C2 C3 a text summarization method applying our mapreduce approach directly to source texts TS and a nave semantic search RAG approach SS CO Uses rootlevel community summaries fewest in number to answer user queries C1 Uses highlevel community summaries to answer queries These are subcommunities of C0 if present otherwise C0 communities projected down C2 Uses intermediatelevel community summaries to answer queries These are subcommunities of C1 if present otherwise C1 communities projected down C3 Uses lowlevel community summaries greatest in number to answer queries These are subcommunities of C2 if present otherwise C2 communities projected down TS The same method as in subsection 26 except source texts rather than community summaries are shuffled and chunked for the mapreduce summarization stages SS An implementation of nave RAG in which text chunks are retrieved and added to the available context window until the specified token limit is reachedThe size of the context window and the prompts used for answer generation are the same across all six conditions except for minor modifications to reference styles to match the types of context information used Conditions only differ in how the contents of the context window are createdThe graph index supporting conditions C0C3 was created using our generic prompts for entity and relationship extraction only with entity types and fewshot examples tailored to the domain of the data The graph indexing process used a context window size of 600 tokens with 1 gleaning for the Podcast dataset and 0 gleanings for the News dataset 34 MetricsLLMs have been shown to be good evaluators of natural language generation achieving stateoftheart or competitive results compared against human judgements Wang et al 2023a Zheng et al 2024 While this approach can generate referencebased metrics when gold standard answers are known it is also capable of measuring the qualities of generated texts eg fluency in a referencefree style Wang et al 2023a as well as in headtohead comparison of competing outputs LLMasajudge Zheng et al 2024 LLMs have also shown promise at evaluating the performance of conventional RAG systems automatically evaluating qualities like context relevance faithfulness and answer relevance RAGAS Es et al 2023Given the multistage nature of our Graph RAG mechanism the multiple conditions we wanted to compare and the lack of gold standard answers to our activitybased sensemaking questions we decided to adopt a headtohead comparison approach using an LLM evaluator We selected three target metrics capturing qualities that are desirable for sensemaking activities as well as a control metric directness used as an indicator of validity Since directness is effectively in opposition to comprehensiveness and diversity we would not expect any method to win across all four metricsOur headtohead measures computed using an LLM evaluator are as follows Comprehensiveness How much detail does the answer provide to cover all aspects and details of the question Diversity How varied and rich is the answer in providing different perspectives and insights on the question Empowerment How well does the answer help the reader understand and make informed judgements about the topic Directness How specifically and clearly does the answer address the questionFor our evaluation the LLM is provided with the question target metric and a pair of answers and asked to assess which answer is better according to the metric as well as why It returns the winner if one exists otherwise a tie if they are fundamentally similar and the differences are negligible To account for the stochasticity of LLMs we run each comparison five times and use mean scores Table 2 shows an example of LLMgenerated assessment", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4089, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "e149a73c-d513-4ce8-9cd2-329b55fe389f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f5085ed6-51f5-42b5-b3f9-dc86c09b5f72", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "f5cfdb831ff2a7c26ba9124d2b9676cbd5cd6956da9b19fda1ec07ee3e2d3411", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Overview of Prominent Public Figures in EntertainmentThe entertainment industry is vast and diverse encompassing film television music sports and digital media Certain public figures stand out due to their significant contributions and influence across these sectors The following summary highlights key individuals who are repeatedly mentioned in various entertainment articles reflecting their impact and presence within the industry Actors and Directors Public Figures in Controversy Musicians and Executives Athletes and Coaches Influencers and EntrepreneursThe repeated mention of these figures in entertainment articles signifies their ongoing relevance and the publics interest in their work Their influence spans across various aspects of entertainment from shaping cultural narratives in film and television to driving trends in music and digital media These individuals not only contribute to their respective fields but also influence the broader cultural landscape often becoming central figures in social discussions and public discourse Public Figures MentionedPublic figures who are repeatedly mentioned across various entertainment articles include Taylor Swift Travis Kelce Britney Spears and Justin Timberlake These individuals have been highlighted for various reasons ranging from their professional achievements to their personal livesTaylor Swift  Travis Kelce  Britney Spears  Justin Timberlake These figures are frequently covered due to their highprofile status and the publics interest in their careers and personal lives Their activities whether in music sports or personal relationships have significant cultural and economic impacts as evidenced by the media coverage and public reactions Comparative Analysis ComprehensivenessWinner1 Graph RAGAnswer 1 is better because it provides a more comprehensive and detailed list of public figures from a wider range of entertainment sectors including film television music sports gaming and digital media It also includes specific examples of their contributions and the impact they have on their respective fields as well as mentions of controversies and their implications Answer 2 while detailed in its coverage of a few individuals is limited to a smaller number of public figures and focuses primarily on their personal lives and relationships rather than a broad spectrum of their professional influence across the entertainment industry DiversityWinner1 Graph RAGAnswer 1 is better because it provides a more varied and rich response by covering a wide range of public figures from different sectors of the entertainment industry including film television music sports gaming and digital media It offers insights into the contributions and influence of these figures as well as controversies and their impact on public discourse The answer also cites specific data sources for each mentioned figure indicating a diverse range of evidence to support the claims In contrast Answer 2 focuses on a smaller group of public figures primarily from the music industry and sports and relies heavily on a single source for data which makes it less diverse in perspectives and insights EmpowermentWinner1 Graph RAGAnswer 1 is better because it provides a comprehensive and structured overview of public figures across various sectors of the entertainment industry including film television music sports and digital media It lists multiple individuals providing specific examples of their contributions and the context in which they are mentioned in entertainment articles along with references to data reports for each claim This approach helps the reader understand the breadth of the topic and make informed judgments without being misled In contrast Answer 2 focuses on a smaller group of public figures and primarily discusses their personal lives and relationships which may not provide as broad an understanding of the topic While Answer 2 also cites sources it does not match the depth and variety of Answer 1 DirectnessWinner2 Nave RAGAnswer 2 is better because it directly lists specific public figures who are repeatedly mentioned across various entertainment articles such as Taylor Swift Travis Kelce Britney Spears and Justin Timberlake and provides concise explanations for their frequent mentions Answer 1 while comprehensive includes a lot of detailed information about various figures in different sectors of entertainment which while informative does not directly answer the question with the same level of conciseness and specificity as Answer 2 Example Question for the News Article DatasetTable 2 Example question for the News article dataset with generated answers from Graph RAG C2 and Nave RAG as well as LLMgenerated assessments", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4909, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "cca54c95-f512-4626-af9b-87b57e2c759f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed1f6401-4b2b-4d20-a2e9-5bce80a45674", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "9860d87b59c78feec9c73c8b759c96787e0ca423f858756096aa0fc3ba131de6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Podcast transcriptsSSTSC0C1C2C3508372757879175050525756285050475051254853504850224350525048214449505250 Comprehensiveness Diversity Empowerment DirectnessSSTSC0C1C2C3508072757979205056596264284450484648254152504245213854585041213652555950Figure 4 Headtohead win rate percentages of row condition over column condition across two datasets four metrics and 125 questions per comparison each repeated five times and averaged The overall winner per dataset and metric is shown in bold Selfwin rates were not computed but are shown as the expected 50 for reference All Graph RAG conditions outperformed nave RAG on comprehensiveness and diversity Conditions C1C3 also showed slight improvements in answer comprehensiveness and diversity over TS global text summarization without a graph index 35 ConfigurationThe effect of context window size on any particular task is unclear especially for models like gpt4turbo with a large context size of 128k tokens Given the potential for information to be lost in the middle of longer contexts Kuratov et al 2024 Liu et al 2023 we wanted to explore the effects of varying the context window size for our combinations of datasets questions and metrics In particular our goal was to determine the optimum context size for our baseline condition SS and then use this uniformly for all querytime LLM use To that end we tested four context window sizes 8k 16k 32k and 64k Surprisingly the smallest context window size tested 8k was universally better for all comparisons on comprehensiveness average win rate of 581 while performing comparably with larger context sizes on diversity average win rate  524 and empowerment average win rate  513 Given our preference for more comprehensive and diverse answers we therefore used a fixed context window size of 8k tokens for the final evaluation 36 ResultsThe indexing process resulted in a graph consisting of 8564 nodes and 20691 edges for the Podcast dataset and a larger graph of 15754 nodes and 19520 edges for the News dataset Table 3 shows the number of community summaries at different levels of each graph community hierarchyGlobal approaches vs nave RAG As shown in Figure 4 global approaches consistently outperformed the nave RAG SS approach in both comprehensiveness and diversity metrics across datasets Specifically global approaches achieved comprehensiveness win rates between 7283 for Podcast transcripts and 7280 for News articles while diversity win rates ranged from 7582 and 6271 respectively Our use of directness as a validity test also achieved the expected results ie that nave RAG produces the most direct responses across all comparisons", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "506f756e-4371-4326-abb0-35816c7b966c", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec745805-b431-48b4-b82c-6107243d2d58", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e6b7d9fb1ef245bcbb4a510303f39719d87793fce80dcf3cd96102a63874ae4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "068c13ee-e8b8-43ef-ac8e-c515d07ef1d4", "node_type": "1", "metadata": {}, "hash": "7fc6de3f293b14cc332203d259657abd99adfb01c2ae0dd5487912ace031c875", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Podcast Transcripts News ArticlesUnitsC0C1C2C3TS      3436796913101669     Tokens266572257565657207461001014611      Max26222558735100     Table 3 Number of context units community summaries for C0C3 and text chunks for TS corresponding token counts and percentage of the maximum token count Mapreduce summarization of source texts is the most resourceintensive approach requiring the highest number of context tokens Rootlevel community summaries C0 require dramatically fewer tokens per query 9x43xCommunity summaries vs source texts When comparing community summaries to source texts using Graph RAG community summaries generally provided a small but consistent improvement in answer comprehensiveness and diversity except for rootlevel summaries Intermediatelevel summaries in the Podcast dataset and lowlevel community summaries in the News dataset achieved comprehensiveness win rates of 57 and 64 respectively Diversity win rates were 57 for Podcast intermediatelevel summaries and 60 for News lowlevel community summaries Table 3 also illustrates the scalability advantages of Graph RAG compared to source text summarization for lowlevel community summaries C3 Graph RAG required 2633 fewer context tokens while for rootlevel community summaries C0 it required over 97 fewer tokens For a modest drop in performance compared with other global methods rootlevel Graph RAG offers a highly efficient method for the iterative question answering that characterizes sensemaking activity while retaining advantages in comprehensiveness 72 win rate and diversity 62 win rate over nave RAGEmpowerment Empowerment comparisons showed mixed results for both global approaches versus nave RAG SS and Graph RAG approaches versus source text summarization TS Adhoc LLM use to analyze LLM reasoning for this measure indicated that the ability to provide specific examples quotes and citations was judged to be key to helping users reach an informed understanding Tuning element extraction prompts may help to retain more of these details in the Graph RAG index 4 Related Work 41 RAG Approaches and SystemsWhen using LLMs RAG involves first retrieving relevant information from external data sources then adding this information to the context window of the LLM along with the original query Ram et al 2023 Nave RAG approaches Gao et al 2023 do this by converting documents to text splitting text into chunks and embedding these chunks into a vector space in which similar positions represent similar semantics Queries are then embedded into the same vector space with the text chunks of the nearest k vectors used as context More advanced variations exist but all solve the problem of what to do when an external dataset of interest exceeds the LLMs context windowAdvanced RAG systems include preretrieval retrieval postretrieval strategies designed to overcome the drawbacks of Nave RAG while Modular RAG systems include patterns for iterative and dynamic cycles of interleaved retrieval and generation Gao et al 2023 Our implementation of Graph RAG incorporates multiple concepts related to other systems For example our community summaries are a kind of selfmemory Selfmem Cheng et al 2024 for generationaugmented retrieval GAR Mao et al 2020 that facilitates future generation cycles while our parallel generation of community answers from these summaries is a kind of iterative IterRetGen Shao et al 2023 or federated FeB4RAG Wang et al 2024 retrievalgeneration strategy Other systems have also combined these concepts for multidocument summarization CAiRECOVID Su et al 2020 and multihop question answering ITRG Feng et al 2023 IRCoT Trivedi et al 2022 DSP Khattab et al 2022", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3951, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "068c13ee-e8b8-43ef-ac8e-c515d07ef1d4", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec745805-b431-48b4-b82c-6107243d2d58", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e6b7d9fb1ef245bcbb4a510303f39719d87793fce80dcf3cd96102a63874ae4c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "506f756e-4371-4326-abb0-35816c7b966c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "648d307ae672e34a712e5de4429768d283fa8f2405fdb3cd1d19ace89e259d93", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Our use of a hierarchical index and summarization also bears resemblance to further approaches such as generating a hierarchical index of text chunks by clustering the vectors of text embeddings RAPTOR Sarthi et al 2024 or generating a tree of clarifications to answer multiple interpretations of ambiguous questions Kim et al 2023 However none of these iterative or hierarchical approaches use the kind of selfgenerated graph index that enables Graph RAG", "mimetype": "text/plain", "start_char_idx": 3952, "end_char_idx": 4423, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "738095aa-f979-4836-9819-d21592789eba", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a486463-97aa-46b1-a190-cfc56fac532e", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e1ad53ef9879cb94e58810412154c2d54d5c56d1dc74ab5a193ddf72c56a7abf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " 42 Graphs and LLMsUse of graphs in connection with LLMs and RAG is a developing research area with multiple directions already established These include using LLMs for knowledge graph creation Trajanoska et al 2023 and completion Yao et al 2023 as well as for the extraction of causal graphs Ban et al 2023 Zhang et al 2024 from source texts They also include forms of advanced RAG Gao et al 2023 where the index is a knowledge graph KAPING Baek et al 2023 where subsets of the graph structure GRetriever He et al 2024 or derived graph metrics GraphToolFormer Zhang 2023 are the objects of enquiry where narrative outputs are strongly grounded in the facts of retrieved subgraphs SURGE Kang et al 2023 where retrieved eventplot subgraphs are serialized using narrative templates FABULA Ranade and Joshi 2023 and where the system supports both creation and traversal of textrelationship graphs for multihop question answering Wang et al 2023b In terms of opensource software a variety of graph databases are supported by both the LangChain LangChain 2024 and LlamaIndex LlamaIndex 2024 libraries while a more general class of graphbased RAG applications is also emerging including systems that can create and reason over knowledge graphs in both Neo4J NaLLM Neo4J 2024 and NebulaGraph GraphRAG NebulaGraph 2024 formats Unlike our Graph RAG approach however none of these systems use the natural modularity of graphs to partition data for global summarization 5 DiscussionLimitations of evaluation approach Our evaluation to date has only examined a certain class of sensemaking questions for two corpora in the region of 1 million tokens More work is needed to understand how performance varies across different ranges of question types data types and dataset sizes as well as to validate our sensemaking questions and target metrics with end users Comparison of fabrication rates eg using approaches like SelfCheckGPT Manakul et al 2023 would also improve on the current analysisTradeoffs of building a graph index We consistently observed Graph RAG achieve the best headtohead results against other methods but in many cases the graphfree approach to global summarization of source texts performed competitively The realworld decision about whether to invest in building a graph index depends on multiple factors including the compute budget expected number of lifetime queries per dataset and value obtained from other aspects of the graph index including the generic community summaries and the use of other graphrelated RAG approachesFuture work The graph index rich text annotations and hierarchical community structure supporting the current Graph RAG approach offer many possibilities for refinement and adaptation This includes RAG approaches that operate in a more local manner via embeddingbased matching of user queries and graph annotations as well as the possibility of hybrid RAG schemes that combine embeddingbased matching against community reports before employing our mapreduce summarization mechanisms This rollup operation could also be extended across more levels of the community hierarchy as well as implemented as a more exploratory drill down mechanism that follows the information scent contained in higherlevel community summaries 6 ConclusionWe have presented a global approach to Graph RAG combining knowledge graph generation retrievalaugmented generation RAG and queryfocused summarization QFS to support human sensemaking over entire text corpora Initial evaluations show substantial improvements over a nave RAG baseline for both the comprehensiveness and diversity of answers as well as favorable comparisons to a global but graphfree approach using mapreduce source text summarization For situations requiring many global queries over the same dataset summaries of rootlevel communities in the entitybased graph index provide a data index that is both superior to nave RAG and achieves competitive performance to other global methods at a fraction of the token cost An opensource Pythonbased implementation of both global and local Graph RAG approaches is forthcoming at httpsakamsgraphrag", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4304, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "12fcb2d1-091e-472e-bfef-bec41ae99002", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b0ab76-1bc2-456b-84e0-e21eafb8667a", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "d40f5e08ccc0385a89d486d7fd64a36268ecfe3f99ff36816c2800ac232f9a0d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77a83051-73b5-4bde-a106-60b8b6b9668f", "node_type": "1", "metadata": {}, "hash": "3a7d68e0f78278d3511fc5b17e8d1d9f8778234c525f5fa4c416585d825a318f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " AcknowledgementsWe would also like to thank the following people who contributed to the work Alonso Guevara Fernndez Amber Hoak Andrs Morales Esquivel Ben Cutler Billie Rinaldi Chris Sanchez Chris Trevino Christine Caggiano David Tittsworth Dayenne de Souza Douglas Orbaker Ed Clark Gabriel NievesPonce Gaudy Blanco Meneses Kate Lytvynets Katy Smith Mnica Carvajal Nathan Evans Richard Ortega Rodrigo Racanicci Sarah Smith and Shane Solomon ReferencesAchiam J Adler S Agarwal S Ahmad L Akkaya I Aleman F L Almeida D Altenschmidt J Altman S Anadkat S et al 2023 Gpt4 technical report arXiv preprint arXiv230308774Anil R Borgeaud S Wu Y Alayrac JB Yu J Soricut R Schalkwyk J Dai A M Hauth A et al 2023 Gemini a family of highly capable multimodal models arXiv preprint arXiv231211805Baek J Aji A F and Saffari A 2023 Knowledgeaugmented language model prompting for zeroshot knowledge graph question answering arXiv preprint arXiv230604136Ban T Chen L Wang X and Chen H 2023 From query tools to causal architects Harnessing large language models for advanced causal discovery from dataBaumel T Eyal M and Elhadad M 2018 Query focused abstractive summarization Incorporating query relevance multidocument coverage and summary length constraints into seq2seq models arXiv preprint arXiv180107704Blondel V D Guillaume JL Lambiotte R and Lefebvre E 2008 Fast unfolding of communities in large networks Journal of statistical mechanics theory and experiment 200810P10008Brown T Mann B Ryder N Subbiah M Kaplan J D Dhariwal P Neelakantan A Shyam P Sastry G Askell A et al 2020 Language models are fewshot learners Advances in neural information processing systems 3318771901Cheng X Luo D Chen X Liu L Zhao D and Yan R 2024 Lift yourself up Retrievalaugmented text generation with selfmemory Advances in Neural Information Processing Systems 36Dang H T 2006 Duc 2005 Evaluation of questionfocused summarization systems In Proceedings of the Workshop on TaskFocused Summarization and Question Answering pages 4855Es S James J EspinosaAnke L and Schockaert S 2023 Ragas Automated evaluation of retrieval augmented generation arXiv preprint arXiv230915217Feng Z Feng X Zhao D Yang M and Qin B 2023 Retrievalgeneration synergy augmented large language models arXiv preprint arXiv231005149Fortunato S 2010 Community detection in graphs Physics reports 4863575174Gao Y Xiong Y Gao X Jia K Pan J Bi Y Dai Y Sun J and Wang H 2023 Retrievalaugmented generation for large language models A survey arXiv preprint arXiv231210997Goodwin T R Savery M E and DemnerFushman D 2020 Flight of the pegasus", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2978, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "77a83051-73b5-4bde-a106-60b8b6b9668f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b0ab76-1bc2-456b-84e0-e21eafb8667a", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "d40f5e08ccc0385a89d486d7fd64a36268ecfe3f99ff36816c2800ac232f9a0d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "12fcb2d1-091e-472e-bfef-bec41ae99002", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "0fe02d611577c594359b49ff9ea7da0ec3495bd1658aed01a8ba94f61bcb44e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2020 Flight of the pegasus comparing transformers on fewshot and zeroshot multidocument abstractive summarization In Proceedings of COLING International Conference on Computational Linguistics volume 2020 page 5640 NIH Public AccessHe X Tian Y Sun Y Chawla N V Laurent T LeCun Y Bresson X and Hooi B 2024 Gretriever Retrievalaugmented generation for textual graph understanding and question answering arXiv preprint arXiv240207630", "mimetype": "text/plain", "start_char_idx": 2948, "end_char_idx": 3427, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "cc76f242-a34c-42e5-8af1-7297c8acc192", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6af52b0c-3a72-42e6-89f2-07b81abf16e1", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "3a235a4cc02e7cf4e41db1b376b4cda3e2520b617de0f5d61d5bcba9eba7c65b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d8290ca-d8a9-4101-b6a5-36c46e2698b3", "node_type": "1", "metadata": {}, "hash": "7ec39575dd9d00178090a1c51bacd0cc0f100e0f0c57dcab9f95e8c48bf04332", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " ReferencesJacomy M Venturini T Heymann S and Bastian M 2014 Forceatlas2 a continuous graph layout algorithm for handy network visualization designed for the gephi software PLoS ONE 96 e98679 httpsdoiorg101371journalpone0098679Jin D Yu Z Jiao P Pan S He D Wu J Philip S Y and Zhang W 2021 A survey of community detection approaches From statistical modeling to deep learning IEEE Transactions on Knowledge and Data Engineering 35211491170Kang M Kwak J M Baek J and Hwang S J 2023 Knowledge graphaugmented language models for knowledgegrounded dialogue generation arXiv preprint arXiv230518846Khattab O Santhanam K Li X L Hall D Liang P Potts C and Zaharia M 2022 Demonstratesearchpredict Composing retrieval and language models for knowledgeintensive nlp arXiv preprint arXiv221214024Kim G Kim S Jeon B Park J and Kang J 2023 Tree of clarifications Answering ambiguous questions with retrievalaugmented large language models arXiv preprint arXiv231014696Klein G Moon B and Hoffman R R 2006a Making sense of sensemaking 1 Alternative perspectives IEEE intelligent systems 2147073Klein G Moon B and Hoffman R R 2006b Making sense of sensemaking 2 A macrocognitive model IEEE Intelligent systems 2158892Koesten L Gregory K Groth P and Simperl E 2021 Talking datasetsunderstanding data sensemaking behaviours International journal of humancomputer studies 146102562Kuratov Y Bulatov A Anokhin P Sorokin D Sorokin A and Burtsev M 2024 In search of needles in a 11m haystack Recurrent memory finds what llms missLangChain 2024 Langchain graphs httpspythonlangchaincomdocsuse casesgraphLaskar M T R Hoque E and Huang J 2020 Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models In Advances in Artificial Intelligence 33rd Canadian Conference on Artificial Intelligence Canadian AI 2020 Ottawa ON Canada May 1315 2020 Proceedings 33 pages 342348 SpringerLaskar M T R Hoque E and Huang J X 2022 Domain adaptation with pretrained transformers for queryfocused abstractive text summarization Computational Linguistics 482279320Lewis P Perez E Piktus A Petroni F Karpukhin V Goyal N Kttler H Lewis M Yih Wt Rocktaschel T et al 2020 Retrievalaugmented generation for knowledgeintensive nlp tasks Advances in Neural Information Processing Systems 3394599474Liu N F Lin K Hewitt J Paranjape A Bevilacqua M Petroni F and Liang P 2023 Lost in the middle How language models use long contexts arXiv230703172Liu Y and Lapata M 2019 Hierarchical transformers for multidocument summarization arXiv preprint arXiv190513164LlamaIndex 2024 LlamaIndex Knowledge Graph Index", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3024, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "6d8290ca-d8a9-4101-b6a5-36c46e2698b3", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6af52b0c-3a72-42e6-89f2-07b81abf16e1", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "3a235a4cc02e7cf4e41db1b376b4cda3e2520b617de0f5d61d5bcba9eba7c65b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc76f242-a34c-42e5-8af1-7297c8acc192", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "a72af445eafd923f926c96422526a56786931cf14b52ea31943dc1e94898ae39", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "LlamaIndex 2024 LlamaIndex Knowledge Graph Index httpsdocsllamaindexaienstableexamplesindex structsknowledge graphKnowledgeGraphDemohtmlManakul P Liusie A and Gales M J 2023 Selfcheckgpt Zeroresource blackbox hallucination detection for generative large language models arXiv preprint arXiv230308896Mao Y He P Liu X Shen Y Gao J Han J and Chen W 2020 Generationaugmented retrieval for opendomain question answering arXiv preprint arXiv200908553Martin S Brown W M Klavans R and Boyack K 2011 Openord An opensource toolbox for large graph layout SPIE Conference on Visualization and Data Analysis VDAMicrosoft 2023 The impact of large language models on scientific discovery a preliminary study using gpt4", "mimetype": "text/plain", "start_char_idx": 2972, "end_char_idx": 3775, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "eb98d772-785b-43a8-a13b-40ec2036b3be", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfd503dd-865b-44fd-83a7-0895fb4cc3e7", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "b03e99c5e92862688bcda297d11c6ce05f8fe537448bbb4ddd89d777f475293f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "deeef575-0e6f-4604-a356-175f0b3de6d1", "node_type": "1", "metadata": {}, "hash": "763676edc73448e89b19b505821f4ef46046dbb64887a4dcf8137f9291d1a9a2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " ReferencesNebulaGraph 2024 Nebulagraph launches industryfirst graph rag Retrievalaugmented generation with llm based on knowledge graphs httpswwwnebulagraphiopostsgraphRAGNeo4J 2024 Project NaLLM httpsgithubcomneo4jNaLLMNewman M E 2006 Modularity and community structure in networks Proceedings of the national academy of sciences 1032385778582Ram O Levine Y Dalmedigos I Muhlgay D Shashua A LeytonBrown K and Shoham Y 2023 Incontext retrievalaugmented language models Transactions of the Association for Computational Linguistics 1113161331Ranade P and Joshi A 2023 Fabula Intelligence report generation using retrievalaugmented narrative construction arXiv preprint arXiv231013848Sarthi P Abdullah S Tuli A Khanna S Goldie A and Manning C D 2024 Raptor Recursive abstractive processing for treeorganized retrieval arXiv preprint arXiv240118059Scott K 2024 Behind the Tech httpswwwmicrosoftcomenusbehindthetechShao Z Gong Y Shen Y Huang M Duan N and Chen W 2023 Enhancing retrievalaugmented large language models with iterative retrievalgeneration synergy arXiv preprint arXiv230515294Su D Xu Y Yu T Siddique F B Barezi E J and Fung P 2020 Cairecovid A question answering and queryfocused multidocument summarization system for covid19 scholarly information management arXiv preprint arXiv200503975Tang Y and Yang Y 2024 MultiHopRAG Benchmarking retrievalaugmented generation for multihop queries arXiv preprint arXiv240115391Touvron H Martin L Stone K Albert P Almahairi A Babaei Y Bashlykov N Batra S Bhargava P Bhosale S et al 2023 Llama 2 Open foundation and finetuned chat models arXiv preprint arXiv230709288Traag V A Waltman L and Van Eck N J 2019 From Louvain to Leiden guaranteeing wellconnected communities Scientific Reports 91Trajanoska M Stojanov R and Trajanov D 2023 Enhancing knowledge graph construction using large language models ArXiv abs230504676Trivedi H Balasubramanian N Khot T and Sabharwal A 2022 Interleaving retrieval with chainofthought reasoning for knowledgeintensive multistep questions arXiv preprint arXiv221210509Wang J Liang Y Meng F Sun Z Shi H Li Z Xu J Qu J and Zhou J 2023a Is chatgpt a good nlg evaluator a preliminary study arXiv preprint arXiv230304048Wang S Khramtsova E Zhuang S and Zuccon G 2024 Feb4rag Evaluating federated search in the context of retrieval augmented generation arXiv preprint arXiv240211891Wang Y Lipka N Rossi R A Siu A Zhang R and Derr T 2023b Knowledge graph prompting for multidocument question answeringXu Y and Lapata M 2021", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2917, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "deeef575-0e6f-4604-a356-175f0b3de6d1", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfd503dd-865b-44fd-83a7-0895fb4cc3e7", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "b03e99c5e92862688bcda297d11c6ce05f8fe537448bbb4ddd89d777f475293f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb98d772-785b-43a8-a13b-40ec2036b3be", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "a759037e95fa5cca94c55f8918240421d2acedd1aaa05ba2c017c74f07f13e34", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Xu Y and Lapata M 2021 Text summarization with latent queries arXiv preprint arXiv210600104Yang Z Qi P Zhang S Bengio Y Cohen W W Salakhutdinov R and Manning C D 2018 HotpotQA A dataset for diverse explainable multihop question answering In Conference on Empirical Methods in Natural Language Processing EMNLPYao Jg Wan X and Xiao J 2017 Recent advances in document summarization Knowledge and Information Systems 53297336", "mimetype": "text/plain", "start_char_idx": 2888, "end_char_idx": 3375, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "768ab3bc-03e3-4545-928a-e0e2f13d9056", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68a01efd-b8fa-403c-ac0a-9f548ade6956", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "8ed714d99bbb0060e8422cf67e29353e0ccc875dda9cd5f403f06628698081ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " ReferencesYao L Peng J Mao C and Luo Y 2023 Exploring large language models for knowledge graph completionZhang J 2023 Graphtoolformer To empower llms with graph reasoning ability via prompt augmented by chatgpt arXiv preprint arXiv230411116Zhang Y Zhang Y Gan Y Yao L and Wang C 2024 Causal graph discovery with retrievalaugmented generation based large language models arXiv preprint arXiv240215301Zheng L Chiang WL Sheng Y Zhuang S Wu Z Zhuang Y Lin Z Li Z Li D Xing E et al 2024 Judging llmasajudge with mtbench and chatbot arena Advances in Neural Information Processing Systems 36", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 687, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}]}, "b824c02f4c2278c1c94b6bf0df57aefa6ec1a3063662e9cfb3d00be4e6e6fc27": {"nodes": [{"__data__": {"id_": "a7d67b37-04a6-4dc9-bcd4-26d31fde6c44", "embedding": [-0.05240713432431221, -0.004472801461815834, -0.024007407948374748, -0.041361305862665176, -0.01793775148689747, -0.05238333344459534, 0.018768778070807457, -0.03412846103310585, -0.02261047065258026, 0.006695902906358242, -0.017174091190099716, 0.04021906107664108, -0.04604293778538704, 0.007635380607098341, 0.008624219335615635, 0.02388574369251728, -0.023286115378141403, -0.019605258479714394, -0.041966237127780914, 0.013537469319999218, 0.015509253367781639, -0.018641576170921326, 0.03847035765647888, 0.010068503208458424, 0.014851905405521393, 0.04129177704453468, -0.008100044913589954, -0.032697584480047226, -0.005438889376819134, 0.01995554193854332, 0.00902548711746931, -0.015199713408946991, 0.057914406061172485, -0.045105233788490295, -0.015389818698167801, -0.005786089226603508, 0.0008867545984685421, -0.0019028736278414726, -0.0547625795006752, 0.019998982548713684, -0.03224087134003639, 0.02338283509016037, 0.0046571651473641396, -0.05951809138059616, 0.019866500049829483, -0.02574697509407997, -0.005595742259174585, -0.032223042100667953, 0.0122887147590518, -0.02009941078722477, -0.04793642461299896, -0.0028414952103048563, 0.030205247923731804, -0.005026241764426231, 0.005798303987830877, 0.049232978373765945, -0.04700810834765434, 0.0004638086829800159, -0.06182266026735306, 0.023078158497810364, -0.011904685758054256, 0.025120938196778297, -0.033534955233335495, -0.028398839756846428, 0.0564173087477684, 0.02874392457306385, 0.00895708054304123, 0.03991590067744255, -0.006014872342348099, -0.016827205196022987, -0.0007158131338655949, 0.0216147992759943, -0.03831852972507477, -0.04604332149028778, -0.06763556599617004, 0.02567960135638714, 0.008173851296305656, -0.0011799321509897709, 0.0025627396535128355, 0.039722975343465805, -0.006899985484778881, 0.009026095271110535, -0.009198121726512909, -0.030924813821911812, -0.02878732606768608, -0.006330305244773626, -0.020286034792661667, 0.050128690898418427, 0.019238462671637535, 0.003860984230414033, -0.02098623849451542, 0.0018500594887882471, 0.009931846521794796, -0.02998732589185238, -0.03678901866078377, -0.0027312401216477156, -0.03781659156084061, 0.027178345248103142, 0.009282046929001808, 0.023220553994178772, 0.05775453522801399, 0.043772079050540924, -0.04588007181882858, -0.012039613910019398, 0.017751220613718033, -0.003521509002894163, 0.013869734480977058, 0.00808468647301197, 9.225087705999613e-05, -0.031665511429309845, -0.009048598818480968, 0.03958611190319061, -0.020297547802329063, 0.04802209138870239, -0.02478715591132641, -0.01810278929769993, -0.02139134705066681, -0.020545288920402527, 0.03446269407868385, -0.018084989860653877, 0.0033202338963747025, 0.006675748620182276, 0.07322270423173904, 0.010872146114706993, -0.0051266890950500965, 0.03206558898091316, 0.021501749753952026, 0.007231567054986954, 0.02141714096069336, -0.007959292270243168, -0.0018658061744645238, 0.010142221115529537, -0.011972551234066486, 0.0034534209407866, -0.018538355827331543, -0.03213028609752655, 0.03233705461025238, -0.04478825256228447, -0.02658260054886341, -0.01888430491089821, 0.0253969244658947, 0.07216431200504303, -0.046543437987565994, -0.05445104464888573, 0.026489822193980217, -0.05855480954051018, -0.004696059972047806, 0.049609649926424026, -0.014529540203511715, -0.004555881954729557, -0.02849583700299263, -0.011059409007430077, 0.012133261188864708, 0.032101135700941086, 0.0028057226445525885, -0.05712166801095009, 0.038843099027872086, 0.04175536334514618, -0.059215787798166275, 0.053320977836847305, 0.020094268023967743, 0.030787454918026924, -0.013004033826291561, -0.004883860237896442, 0.017699124291539192, -0.01270770002156496, 0.046963293105363846, -0.01884486712515354, -0.008674041368067265, -0.06378113478422165, 0.0023315916769206524, -0.036989763379096985, 0.041500698775053024, -0.006300022359937429, 0.033620383590459824, 0.019031070172786713, 0.07694709300994873, 0.02450396865606308, 0.023433011025190353, -0.00991425197571516, 0.01180939469486475, 0.01130386721342802, -0.015284384600818157, 0.017402496188879013, -0.014431011863052845, -0.004629447590559721, -0.06234001740813255, -0.017028549686074257, 0.006698402110487223, 0.008094951510429382, -0.015133051201701164, -0.03795276954770088, 0.030029362067580223, 0.031129080802202225, -0.014788232743740082, -0.025445599108934402, -0.016349803656339645, 0.004864754155278206, -0.021450495347380638, -0.029894409701228142, 0.003944218624383211, 0.055595215409994125, -0.007207357790321112, 0.021068155765533447, -0.0284266360104084, -0.008060529828071594, 0.004078392870724201, -0.0778212696313858, 0.029363706707954407, 0.01783650740981102, 0.04659952223300934, -0.0036429583560675383, 0.017208145931363106, -0.0003564131329767406, -0.005783299915492535, 0.02998216263949871, -0.015792541205883026, -0.021774496883153915, 0.03090432658791542, -0.00676954397931695, -0.030256442725658417, 0.011107993312180042, 0.0010762076126411557, -0.035612430423498154, 0.03733065351843834, -0.0002643519837874919, -0.00460899667814374, 0.04373341053724289, 0.05489753559231758, -0.04917902126908302, -0.006514429580420256, 5.431391764432192e-05, -0.011003711260855198, -0.04672463610768318, 0.0191095769405365, 0.003704328089952469, -0.015406906604766846, -0.0074627697467803955, 0.01780577376484871, 0.03816364333033562, -0.043205421417951584, -0.01706787757575512, -0.0037025553174316883, 0.009064281359314919, -0.05174316465854645, -0.0146035710349679, 0.009338120929896832, 0.06418564915657043, -0.032697901129722595, -0.03897921368479729, 0.03977155685424805, 0.015253251418471336, -0.011769224889576435, -0.020487021654844284, 0.03105904720723629, 0.02653338387608528, 0.06440804898738861, -0.016843292862176895, -0.012549133040010929, -0.02903255820274353, -0.008423244580626488, 0.023281607776880264, 0.024152036756277084, 0.023488368839025497, 0.0074418154545128345, 0.00860963761806488, -0.04006011411547661, -0.016284072771668434, 0.019473634660243988, 0.019321685656905174, -0.03031829372048378, 0.003812165465205908, -0.017380230128765106, -0.024310104548931122, -0.00470178434625268, 0.03576004505157471, -0.0019988457206636667, -0.015354984439909458, 0.12087257206439972, 0.03472505509853363, -0.016185354441404343, 0.05539143085479736, 0.06064806506037712, 0.005228094290941954, 0.053955525159835815, -0.0017954250797629356, -0.01962648518383503, -0.0223837960511446, -0.0020117899402976036, 0.007368435617536306, 0.009731308557093143, 0.015404695644974709, 0.05652154982089996, -0.0345187745988369, -0.0733843669295311, -0.012623346410691738, -0.002394659910351038, -0.1776338368654251, -0.032956793904304504, -0.020778175443410873, 0.021411707624793053, 0.004661067854613066, 0.01905681937932968, -0.02489238604903221, -0.03398501127958298, 0.0010266659082844853, 0.03330312669277191, -0.00031290960032492876, -0.05571486055850983, -0.05110524594783783, -0.015531044453382492, -0.0514315664768219, 0.03788279369473457, -0.008119631558656693, 0.01383251789957285, 0.010895169340074062, -0.027765559032559395, -0.01541769877076149, -0.03196414187550545, 0.03233877569437027, -0.0005831453599967062, 0.006923276465386152, -0.028840957209467888, 0.029403680935502052, 0.0016674087382853031, -0.023862864822149277, -0.0009790853364393115, -0.02112036943435669, -0.031215447932481766, 0.010129677131772041, 0.017545854672789574, -0.01852481998503208, 0.03701280802488327, 0.013143271207809448, -0.027873283252120018, -0.03703226149082184, -0.011079732328653336, -0.045933566987514496, 0.03227219730615616, -0.006961676757782698, -0.0015862347790971398, -0.023518964648246765, 0.005901788827031851, 0.034654926508665085, -0.019183361902832985, -0.042959678918123245, 0.01334151066839695, -0.004771953448653221, -0.004155088681727648, -0.01409282349050045, 0.004931219853460789, -0.04836598038673401, -0.028125669807195663, -0.05367615073919296, 0.008788498118519783, -0.0020443578250706196, -0.013878910802304745, 0.012895246036350727, 0.03532358631491661, -0.014746187254786491, -0.05531258136034012, -0.027057139202952385, 0.03369024768471718, 0.05443841964006424, 0.012693159282207489, 0.04400599002838135, -0.029025115072727203, 0.06042226031422615, -0.047499340027570724, 0.0010566140990704298, 0.00475868908688426, 0.0019489254336804152, 0.05888459458947182, -0.003200457664206624, 0.011453064158558846, -0.018058469519019127, -0.058193452656269073, -0.02584385871887207, -0.030145587399601936, 0.00905383937060833, 0.008833032101392746, -0.027160538360476494, 0.037863027304410934, 0.018075449392199516, 0.02258003130555153, 0.04074237868189812, 0.23818068206310272, -0.004342517349869013, 0.008369081653654575, -0.04976735636591911, 0.02568700723350048, -0.024644950404763222, -0.007881421595811844, 0.010818692855536938, 0.012114666402339935, -0.01944315806031227, 0.028727944940328598, 0.06164099648594856, 0.016312995925545692, -0.00875762477517128, -0.0032955484930425882, 0.07616221159696579, -0.02831450290977955, 0.012781277298927307, 0.05185669660568237, -0.013164309784770012, -0.004828516393899918, -0.02433811128139496, -0.019418910145759583, 0.04671523720026016, -0.024351749569177628, -0.0202216487377882, -0.011861314065754414, -0.03445374593138695, -0.01668669655919075, 0.04601409286260605, -0.014649835415184498, -0.0016109205316752195, 0.03575098514556885, -0.023742957040667534, 0.0027990764938294888, -0.009343354031443596, 0.040083982050418854, -0.02362639084458351, -0.030887803062796593, -0.0031196412164717913, -0.007934085093438625, -0.05544204264879227, -0.04417561739683151, 0.021090703085064888, 0.005094179417937994, -0.038365550339221954, -0.03284154087305069, -0.016061313450336456, 0.006928688380867243, 0.021507808938622475, -0.003835160518065095, -0.04879293590784073, -0.040900953114032745, 0.020368007943034172, 0.007520584389567375, -0.009658236987888813, -0.02084491215646267, -0.030147524550557137, 0.002876694779843092, -9.734549530548975e-05, 0.026960749179124832, -0.011448447592556477, -0.0430690199136734, -0.012044512666761875, 0.007002635393291712, -0.00471471855416894, 0.022901885211467743, -0.033509451895952225, 0.030994532629847527, 0.030495328828692436, 0.01772557571530342, 0.03056580200791359, 0.056783657521009445, -0.033927761018276215, 0.048976924270391464, 0.004124936647713184, 0.03995141759514809, 0.017611375078558922, 0.0036214350257068872, 0.007514231372624636, -0.036796778440475464, 0.03928288072347641, 0.017937637865543365, 0.005644313991069794, 0.032812513411045074, 0.04492443799972534, 0.023657342419028282, 0.058308228850364685, -0.044196031987667084, -0.008109641261398792, -0.013320260681211948, -0.02096562273800373, -0.014960931614041328, 0.006366194691509008, 0.031216489151120186, -0.015400388278067112, -0.028764979913830757, -0.038584984838962555, -0.03915081545710564, -0.048069000244140625, -0.001403334317728877, -0.000676386000122875, -0.003180793486535549, 0.01055164448916912, 0.028675422072410583, 0.01167482789605856, -0.04533826559782028, -0.01436906773597002, -0.018474314361810684, -0.007799604907631874, -0.036695417016744614, -0.0037064237985759974, -0.002316173864528537, -0.02747391164302826, 0.02491382323205471, 0.04388787969946861, 0.0072000534273684025, 0.011287884786725044, 0.043012794107198715, 0.006226719822734594, -0.009895959869027138, 0.016193542629480362, -0.02825840748846531, 0.0006246492266654968, 0.05418296530842781, 0.001591948326677084, -0.021420052275061607, 0.002745397388935089, -0.020271096378564835, 0.018239401280879974, 0.04417749494314194, -0.026905681937932968, 0.019641689956188202, 0.004958816803991795, -2.0071971448487602e-05, 0.012660649605095387, -0.01742829754948616, 0.00917023979127407, -0.029550205916166306, -0.0015223863301798701, -0.061178453266620636, -0.006044285837560892, -0.005610122811049223, -0.032799530774354935, 0.03528963774442673, 0.04567711800336838, -0.00472772354260087, -0.026835912838578224, 0.04658883810043335, 0.012482907623052597, 0.01835252158343792, 0.015739908441901207, 0.028306666761636734, 0.0018831422785297036, 0.006708407308906317, 0.025191621854901314, -0.007458661217242479, 0.005028682295233011, 0.011150258593261242, -0.065936379134655, -0.03591776266694069, -0.04405383765697479, 0.01915162056684494, 0.03442427143454552, 0.011472712270915508, 0.015083115547895432, -0.012706327252089977, 0.038354936987161636, -0.019793080165982246, -0.028490228578448296, -0.04703802987933159, -0.023596297949552536, -0.06530794501304626, 0.02608686313033104, -0.010253338143229485, -0.03159525990486145, -0.011274383403360844, -0.03544105216860771, 0.0020688134245574474, 0.009301143698394299, 0.03209543600678444, -0.017314380034804344, -0.023573873564600945, 0.01497062761336565, 0.03393695130944252, 0.03976723179221153, 0.025169536471366882, -0.009714432992041111, 0.016032002866268158, -0.03608622029423714, -0.026401011273264885, 0.09178807586431503, 0.02013440616428852, 0.009228312410414219, 0.017483944073319435, -0.021742431446909904, 0.028591569513082504, 0.01901276968419552, 0.004132882226258516, -0.03466758504509926, 0.004629196599125862, -0.01911170780658722, 0.006782190874218941, 0.004580455832183361, -0.050290461629629135, 0.003101727459579706, -0.01862417533993721, -0.002622083527967334, -0.06379447132349014, -0.0359419509768486, 0.007125372998416424, -0.008572581224143505, -0.02875182405114174, -0.0022613625042140484, -0.08063920587301254, -0.011671075597405434, -0.013533473014831543, 0.047160375863313675, 0.001963187474757433, -0.008741364814341068, -0.01750328205525875, -0.015150424093008041, -0.014803053811192513, -0.07389651983976364, -0.008092869073152542, 0.009242497384548187, -0.004397103562951088, 0.0031957668252289295, -0.0008664618362672627, 0.003759077750146389, 0.007015684153884649, -0.03782093897461891, 0.007452830672264099, -0.01535994466394186, -0.03001563251018524, 0.01708538457751274, 0.007934663444757462, 0.029220154508948326, -0.031630195677280426, -0.009335351176559925, 0.010667790658771992, -0.01876446232199669, 0.017405707389116287, 0.04533552750945091, -0.0011594763491302729, -0.017096471041440964, -0.05373409017920494, -0.012817807495594025, 0.03454841300845146, 0.05977993831038475, -0.00013840349856764078, -0.025388795882463455, 0.04360417649149895, 0.006766237784177065, 0.011549514718353748, 0.008527944795787334, -0.03900313749909401, -0.005382366944104433, 0.0338231697678566, -0.0013072428992018104, -0.01990983448922634, 0.006160880904644728, 0.006013890262693167, -0.031037207692861557, -0.03415271267294884, -0.026171306148171425, 0.04683844372630119, -0.017625082284212112, -0.003240578342229128, -0.02231908217072487, -0.01450422778725624, 0.014870612882077694, -0.00746121583506465, -0.00900318194180727, 0.014623591676354408, -0.01233142614364624, -0.062351688742637634, 0.004698862787336111, 0.06431899219751358, -0.007557290140539408, -0.028803622350096703, 0.02682613767683506, 0.04550148919224739, 0.05082995817065239, 0.005799192935228348, -0.002825039206072688, 0.05370524898171425, 0.022822313010692596, 0.026098646223545074, -0.006767462007701397, -0.0023072960320860147, 0.009347459301352501, -0.04236830398440361, 0.022620536386966705, -0.007297198753803968, -0.010338712483644485, -0.009057559072971344, 0.05239295959472656, 0.004583344794809818, -0.014044638723134995, -0.02712455578148365, 0.020983576774597168, 0.028558438643813133, -0.002966254483908415, -0.04059673100709915, 0.047108978033065796, 0.010394790209829807, -0.016761168837547302, 0.07334765791893005, 0.009255158714950085, -0.020460128784179688, -0.030526310205459595, 0.005559232551604509, -0.015510518103837967, 0.0194635521620512, -0.025291765108704567, 0.05924542620778084, -0.011835314333438873, 0.042339202016592026, -0.012391863390803337, 0.0010166900465264916, -0.01828978769481182, -0.05471474304795265, -0.03772459551692009, -0.021561307832598686, 0.0002853842743206769, 0.024093983694911003, -0.01924784854054451, 0.008744386024773121, 0.0033174885902553797, -0.032305777072906494, -0.01622196100652218, 0.021747086197137833, -0.024696383625268936, 0.015491345897316933, 0.017503421753644943, 0.02428257092833519, -0.018436653539538383, 0.028055179864168167, -0.007339532487094402, 0.04611766338348389, 0.0013410451356321573, 0.03386446461081505, -0.022134384140372276, 0.017579663544893265, 0.027674168348312378, -0.0073184659704566, 0.034138184040784836, -0.014473509974777699, -0.0066237980499863625, -0.011512517929077148, 0.01546539831906557, -0.013299559243023396, 0.0020005053374916315, 0.07928764075040817, -0.03477407246828079, -0.03251829370856285, 0.0244093369692564, 0.03256508335471153, -0.008854859508574009, -0.024436814710497856, 0.022535163909196854, 0.02117149718105793, -0.006379894446581602, -0.012934412807226181, -0.0007275037933140993, 0.01652875356376171, -0.0026144294533878565, -0.048094552010297775, -0.015028923749923706, -0.020479854196310043, 0.00040137444739229977, -0.023321418091654778, -0.037743788212537766, -0.020755073055624962, 0.03898025304079056, -0.05510745197534561, 0.03971507400274277, 0.03129195794463158, -0.09220971167087555, -0.010028181597590446, 0.016220223158597946, 0.0017254756530746818, -0.009938481263816357, -0.01299737486988306, 2.892595875891857e-05, -0.03182919695973396, -0.004021357744932175, 0.010493185371160507, -0.008042674511671066, -0.051006611436605453, 0.017351752147078514, -0.0255045797675848, 0.0316673181951046, -0.1377200335264206, 0.002665306907147169, -0.028428934514522552, 0.02583162486553192, -0.008936396799981594, 0.008230327628552914, 0.001039243652485311, -0.015663400292396545, 0.028357500210404396, -0.05873563513159752, 0.0313555970788002, 0.009176939725875854, -0.045161809772253036, -0.015560985542833805, -0.034519609063863754, 0.024125821888446808, 0.013262809254229069, -0.029349280521273613, 0.003953277133405209, 0.039734479039907455, 0.0001720793661661446, -0.005671077873557806, 0.04027027264237404, 0.057465508580207825, 0.002578896703198552, 0.02559160813689232, -0.005372593645006418, -0.06501738727092743, -0.04051235690712929, -0.0061877029947936535, 0.02671763114631176, -0.052611757069826126, 0.0195612795650959, 0.06724520027637482, -0.005240606144070625, -0.011142794042825699, 0.014570146799087524, 0.011038626544177532, -0.010160890407860279, -0.021301470696926117, 0.0020568904001265764, 0.03189479187130928, -0.002612312324345112, 0.025944896042346954, 0.03126721456646919, 0.025548800826072693, -0.006416567135602236, -0.040629200637340546, -0.005798812489956617, 0.00953469518572092, 0.02097397856414318, 0.04101690649986267, -0.038937151432037354, -0.025183917954564095, 0.013502906076610088, -0.0024093606043606997, -0.03518907353281975, -0.0008286669617518783, -0.021216051653027534, 0.02586314082145691, -0.008110178634524345, 0.026515254750847816, -0.041115809231996536, -0.025361934676766396, 0.012608966790139675, 0.00428276089951396, -0.0441124401986599, 0.024105515331029892, -0.0390484593808651, 0.04943150654435158, 0.021619873121380806, -0.020764170214533806, -0.023725446313619614, -0.01097843237221241, 0.02507525309920311, 0.0002941550628747791, 0.015423438511788845, 0.03118766099214554, -0.060336194932460785, -0.017457982525229454, 0.03317924588918686, -0.006577294785529375, -0.04261795058846474, 0.013716368936002254, 0.061306893825531006, -0.01662665605545044, -0.000628393201623112, 0.010793926194310188, -0.03394218906760216, 0.008631917648017406, -0.00988748762756586, -0.01262739859521389, -0.06099967658519745, -0.07220739126205444, -0.0004242135037202388, 0.016603991389274597, -0.029321379959583282, -0.008167950436472893, 0.03015679307281971, 0.0282269474118948, -0.004219322465360165, 0.0005544383893720806, -0.006256148684769869, 0.020542597398161888, 0.019338706508278847, 0.03406398370862007, 0.01918668858706951, 0.004410599824041128, -0.0008894187049008906, 0.016626885160803795, -0.09704785794019699, 0.017497122287750244, -0.0018125528004020452, 0.02136051654815674, -0.08438481390476227, -0.016189243644475937, 0.026548555120825768, -0.00210444163531065, 0.022441577166318893, 0.031960148364305496, 0.01561209000647068, -0.01201027724891901, -0.01214838121086359, -0.007122107315808535, 0.030889004468917847, 0.041478294879198074, 0.03953228145837784, -0.006115743424743414, 0.01557700615376234, 0.0049082026816904545, -0.01758716069161892, -0.054028794169425964, 0.04450071230530739, 0.003140555927529931, 0.030620967969298363, -0.043578702956438065, 0.0003321171388961375, 0.03624803572893143, -0.06546800583600998, -0.03351946547627449, -0.001076485961675644, -0.03700415417551994, -0.030441656708717346, 0.0010351196397095919, -0.023805920034646988, -0.01608467847108841, 0.01067100279033184, 0.0240432471036911, -0.04172474145889282, -0.04944942891597748, 0.04912722483277321, 0.011950886808335781, 0.00864969938993454, 0.020549055188894272, 0.019683469086885452, -0.01889978162944317, 0.002339339582249522, -0.00555908540263772, 0.006414152216166258, 0.11081473529338837, -0.0010097060585394502, -0.04109640046954155, -0.008277255110442638, 0.0015449371421709657, 0.00017995825328398496, 0.0404864177107811, -0.024850282818078995, -0.04033186286687851, -0.05854169279336929, 0.01698671653866768, 0.06581658869981766, 0.027616143226623535, -0.029580073431134224, 0.011055384762585163, 0.06331777572631836, -0.04137277975678444, -0.010872500017285347, 0.010081293061375618, 0.07287897914648056, -0.016446201130747795, 0.004651729948818684, 0.0027086492627859116, 0.01286241039633751, 0.037761736661195755, -0.029699545353651047, -0.0021886583417654037, -0.01851658895611763, 0.028505345806479454, -0.0005072745843790472, 0.014555561356246471, 0.0076444330625236034, -0.018351728096604347, 0.038205891847610474, -0.03270137682557106, 0.06413190066814423, 0.03395608440041542, -0.010845499113202095, 0.0032539197709411383, -0.02582642436027527, 0.03880805894732475, -0.004812854807823896, -0.016527678817510605, -0.0394204780459404, -0.016743110492825508, -0.0008699389873072505, -0.02752302587032318, -0.047685448080301285, -0.03623764589428902, -0.006299370434135199, 0.02464236132800579, 0.011085792444646358, 0.0016199554083868861, -0.0706920400261879, 0.042610734701156616, 0.0048730140551924706, -0.005693551618605852, 0.051791783422231674, 0.0015309136360883713, -0.012058338150382042, -0.0325598269701004, 0.044342927634716034, 0.01940559782087803, -0.019341260194778442, -0.04231126606464386, -0.01306865457445383, 0.011087775230407715, 0.016591155901551247, 0.018542589619755745, 0.004657213110476732, -0.012704625725746155, -0.015760086476802826, -0.014979726634919643, -0.005874790716916323, 0.048978548496961594, 0.06370598822832108, -0.011640630662441254, 0.02064468152821064, 0.037536390125751495, -0.016832496970891953, 0.00559124443680048, -0.01363330613821745, 0.024832798168063164, -0.002573440782725811, -0.007725955918431282], "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cc23039-683e-42ff-b4ba-404a92677b1d", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "9bae910b07e00ab8140e86243b92eb959c0240aadcc5c5c68c84722d31cb1c86", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " From Local to Global A Graph RAG Approach to QueryFocused SummarizationDarren Edge1 Ha Trinh1 Newman Cheng2 Joshua Bradley2 Alex Chao3arXiv240416130v1 csCL 24 Apr 2024 Apurva Mody3 Steven Truitt2 Jonathan Larson11Microsoft Research2Microsoft Strategic Missions and Technologies3Microsoft Office of the CTOdaedgetrinhhanewmanchengjoshbradleyachaomoapurvasteventruittjolarsomicrosoftcomThese authors contributed equally to this work AbstractThe use of retrievalaugmented generation RAG to retrieve relevant information from an external knowledge source enables large language models LLMs to answer questions over private andor previously unseen document collections However RAG fails on global questions directed at an entire text corpus such as What are the main themes in the dataset since this is inherently a queryfocused summarization QFS task rather than an explicit retrieval task Prior QFS methods meanwhile fail to scale to the quantities of text indexed by typical RAG systems To combine the strengths of these contrasting methods we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed Our approach uses an LLM to build a graphbased text index in two stages first to derive an entity knowledge graph from the source documents then to pregenerate community summaries for all groups of closelyrelated entities Given a question each community summary is used to generate a partial response before all partial responses are again summarized in a final response to the user For a class of global sensemaking questions over datasets in the 1 million token range we show that Graph RAG leads to substantial improvements over a nave RAG baseline for both the comprehensiveness and diversity of generated answers An opensource Pythonbased implementation of both global and local Graph RAG approaches is forthcoming at httpsakamsgraphrag 1 IntroductionHuman endeavors across a range of domains rely on our ability to read and reason about large collections of documents often reaching conclusions that go beyond anything stated in the source texts themselves With the emergence of large language models LLMs we are already witnessing attempts to automate humanlike sensemaking in complex domains like scientific discovery Microsoft 2023 and intelligence analysis Ranade and Joshi 2023 where sensemaking is defined asPreprint Under review", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2569, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "0722d552-97ea-4a86-bfad-9a3ed9bf8740", "embedding": [-0.04310031607747078, -0.029273295775055885, -0.014736536890268326, 0.019066251814365387, -0.0036058188416063786, -0.04664437100291252, 0.0021191518753767014, -0.013382423669099808, -0.031037665903568268, 0.011664436198771, -0.03356849402189255, 0.020541196689009666, -0.02684476226568222, 0.009444274939596653, -0.020103784278035164, -0.03199751675128937, 0.0017919476376846433, -0.02152528241276741, 0.019573353230953217, -0.006492708809673786, -0.024121763184666634, -0.004078895319253206, -0.010501950979232788, 0.02092849649488926, -0.02678868919610977, 0.0323437936604023, 0.005721927620470524, 0.01897665299475193, -0.006120394449681044, 0.032718583941459656, -0.007578318007290363, -0.021389584988355637, 0.05225994810461998, 0.0030276537872850895, -0.023146972060203552, -0.04496225342154503, -0.04128040000796318, -0.014131826348602772, -0.023030724376440048, 0.046914421021938324, -0.021881788969039917, -0.005247973836958408, 0.012901363894343376, -0.07319020479917526, 0.026173336431384087, -0.04289799928665161, -0.0019931013230234385, -0.02427365817129612, 0.015080759301781654, -0.013169221580028534, -0.05116559937596321, 0.01763795129954815, 0.04132845252752304, -0.03618382662534714, -0.02134944126009941, 0.05383343622088432, -0.09184319525957108, 0.025631869211792946, -0.03998984396457672, 0.03198402747511864, 0.012175219133496284, -0.010713519528508186, -0.029426278546452522, -0.03890508785843849, -0.0019924365915358067, 0.03987446054816246, 0.020619580522179604, 0.0274493470788002, -0.020766394212841988, -0.03759376332163811, 0.0037210341542959213, 0.03813694417476654, -0.06191060692071915, -0.02172797918319702, -0.04345976188778877, 0.021869264543056488, 0.004002504050731659, -0.06460192054510117, -0.015668392181396484, 0.027544992044568062, 0.011203962378203869, -0.03797447308897972, 0.002888497430831194, -0.024345271289348602, -0.01689922623336315, -0.014611706137657166, -0.04460509866476059, 0.07300087809562683, 0.043762121349573135, 0.034713685512542725, 0.00385587802156806, -0.010007231496274471, -0.0022746198810636997, -0.01983031816780567, -0.0810486450791359, 0.0010652688797563314, -0.026726802811026573, 0.008549733087420464, -0.021061038598418236, 0.025460295379161835, 0.035499297082424164, 0.016195405274629593, -0.04177854210138321, 0.01283048652112484, 0.04788129776716232, -0.019503995776176453, -0.0037894686684012413, -0.0005969236372038722, 0.01989521086215973, 0.004594856407493353, 0.00048616499407216907, 0.01838899962604046, -0.0043335286900401115, 0.029136618599295616, -0.026815539225935936, 0.0019502458162605762, -0.027102848514914513, 0.013081952929496765, 0.041882697492837906, -0.0283123180270195, 0.028423955664038658, 0.0033726582769304514, 0.09090196341276169, -0.011729744262993336, 0.006888337433338165, 0.011632775887846947, 0.012158303521573544, 0.008799868635833263, 0.028739793226122856, 0.007522522937506437, -0.018936453387141228, 0.048645224422216415, -0.0017243758775293827, -0.018765036016702652, 0.019808869808912277, -0.033498942852020264, 0.025374919176101685, -0.024175547063350677, -0.02293148823082447, -0.0314725823700428, 0.03598041087388992, 0.024395853281021118, -0.020912762731313705, -0.06978774815797806, 0.033351507037878036, -0.04469875618815422, -0.005275372881442308, 0.028047965839505196, 0.015754904597997665, 0.014568802900612354, -0.012667888775467873, -0.01802045851945877, 0.017687726765871048, 0.043437566608190536, 0.013394657522439957, -0.024388235062360764, 0.03341265395283699, 0.033446162939071655, -0.03886774554848671, 0.05968926101922989, -0.00758236413821578, 0.02993839420378208, -0.0016905312659218907, -0.00028595319599844515, 0.031818874180316925, -0.05536932498216629, 0.014106039889156818, -0.007970990613102913, -0.004773981869220734, -0.038607366383075714, 0.0047418586909770966, -0.02478935196995735, 0.012983927503228188, -0.01454564556479454, 0.015323415398597717, 0.029200861230492592, 0.05796991288661957, 0.01653534173965454, 0.007029805798083544, -0.0314607210457325, 0.03017202951014042, -0.0121659180149436, -0.029801616445183754, -0.0007628703024238348, -0.011796598322689533, 0.02679666317999363, -0.08910911530256271, -0.013613566756248474, 0.0075507801957428455, 0.003723900532349944, -0.04537840187549591, -0.04244908690452576, 0.03778724744915962, 0.04333382472395897, -0.004736953880637884, 0.003612188156694174, 0.016375485807657242, -0.003737892722710967, 0.014659306965768337, -0.012492354027926922, 0.05915223807096481, 0.06434772163629532, -0.03109077736735344, 0.0026891580782830715, -0.03790026903152466, -0.00814162939786911, -0.0014834603061899543, -0.06427060812711716, -0.016559218987822533, -0.06045001372694969, 0.0314478725194931, 0.015072756446897984, 0.011994843371212482, -0.012193693779408932, -0.014420134015381336, 0.0199942234903574, -0.018653886392712593, -0.01971864141523838, -0.0019975323230028152, -0.03631069138646126, -0.018925735726952553, 0.00014578264381270856, -0.020433060824871063, -0.01281260047107935, 0.00695645110681653, -0.00991168525069952, -0.016272112727165222, 0.009490448981523514, 0.03251097723841667, -0.0593777596950531, -0.030246654525399208, 0.037189435213804245, 0.009219239465892315, -0.023215685039758682, 0.02435392327606678, -0.02408638596534729, -0.01355577353388071, 0.012669901363551617, 0.02492275834083557, 0.007828233763575554, -0.03773430362343788, -0.004061768762767315, 0.012445020489394665, -0.009565341286361217, -0.062086910009384155, -0.022357966750860214, -0.007309257052838802, 0.07355766743421555, -0.012724555097520351, -0.04983336851000786, 0.05920826643705368, 0.03421301394701004, 0.030512796714901924, 0.003299377392977476, 0.02206536754965782, 0.009788842871785164, 0.04477199167013168, -0.004106889944523573, 0.03320560231804848, -0.021080257371068, 0.009990029968321323, 0.020087188109755516, -0.0011596461990848184, 0.0009377323440276086, 0.022148065268993378, -0.01791571080684662, -0.02212437614798546, -0.018886592239141464, 0.04078618809580803, 0.009545805864036083, -0.029607029631733894, 0.006570880301296711, -0.002161898883059621, 0.0004676998942159116, -0.041402336210012436, 0.03942679613828659, -0.01907365396618843, -5.4464417189592496e-05, 0.11018852889537811, 0.020458245649933815, -0.008921570144593716, 0.048975832760334015, 0.03105129301548004, 0.008917776867747307, 0.035496786236763, 4.2181298340437934e-05, -0.0059401122853159904, -0.019175881519913673, 0.010459157638251781, 0.030568839982151985, 0.023104112595319748, 0.0012456729309633374, 0.05703416094183922, -0.022266946732997894, -0.048130687326192856, 0.0024414341896772385, 0.006331229116767645, -0.17104275524616241, -0.040580105036497116, -0.010069357231259346, -0.0031580498907715082, 0.010831245221197605, 0.015109699219465256, -0.02651064284145832, -0.024059901013970375, -0.0034501736517995596, 0.013921125791966915, -0.013166248798370361, -0.06706347316503525, -0.031307369470596313, -0.002416901523247361, -0.0034358010161668062, 0.04553196206688881, -0.01154854241758585, 0.026831435039639473, 0.00852617621421814, -0.025408975780010223, -0.005790801253169775, -0.02902643196284771, 0.010798702947795391, -0.014240243472158909, -0.02947373129427433, -0.006544485222548246, 0.05445033311843872, 0.009995637461543083, -0.02201409637928009, -0.03637236729264259, 0.003760508494451642, -0.01936202123761177, 0.008904890157282352, 0.030071508139371872, -0.0009928024373948574, 0.056736353784799576, 0.020931744948029518, -0.00336604961194098, -0.03372892737388611, -0.012794981710612774, 0.008894258178770542, 0.0540037639439106, -0.002637310652062297, 0.0322299562394619, -0.01026936061680317, -0.008483831770718098, 0.03761187940835953, -0.024126911535859108, -0.07676886022090912, -0.006948653608560562, -0.025911375880241394, 0.004675577394664288, 0.007209361996501684, -0.003623758675530553, -0.05329539626836777, -0.02782859466969967, -0.02493825927376747, 0.019342180341482162, 0.02693166956305504, 0.020660018548369408, -0.0005625406629405916, -0.01148045901209116, -0.025690514594316483, 0.004328042734414339, -0.03393309935927391, 0.018942495808005333, 0.08646062761545181, 0.014920086599886417, 0.03261060267686844, -0.011974828317761421, 0.05681617930531502, -0.011415218934416771, -0.007629211526364088, 0.028012633323669434, 0.0034584614913910627, 0.02937261015176773, -0.00046128532267175615, 0.028533989563584328, -0.0058455318212509155, -0.08378864079713821, -0.03719376400113106, -0.0340331606566906, 0.0011844031978398561, 0.015436728484928608, -0.02397657185792923, 0.044404782354831696, -0.0023825564421713352, 0.021132389083504677, 0.0033970638178288937, 0.2328624427318573, 0.003199924947693944, 0.011864797212183475, -0.06355476379394531, 0.03707309067249298, 0.014291823841631413, 0.03508066013455391, 0.052098583430051804, -0.00155371124856174, -0.00037733244244009256, -0.002254523802548647, 0.028681259602308273, 0.012704156339168549, 0.004523810930550098, 0.0288386270403862, 0.03589359298348427, -0.02480032481253147, 0.0037446513306349516, 0.04630854353308678, -0.001667401404120028, 0.017685947939753532, -0.0582883358001709, 0.02185300923883915, 0.07482457160949707, -0.043444566428661346, -0.010587585158646107, -0.020146654918789864, 0.006251758895814419, -0.003963375464081764, 0.02252913825213909, -0.03812399134039879, 0.009534919634461403, 0.014540658332407475, 0.0048353346064686775, 0.0005215614219196141, 0.012866939418017864, 0.030051348730921745, -7.41900730645284e-05, -0.03169483318924904, 0.0003508587833493948, -0.015318292193114758, -0.058416202664375305, -0.04343707114458084, 0.002325137611478567, 0.03945981711149216, -0.037264104932546616, -0.01666524074971676, -0.034199297428131104, 0.01778293028473854, 0.010471576824784279, -0.003394051920622587, -0.06654234230518341, -0.014853239990770817, 0.002436627633869648, 0.01669958233833313, 0.009666903875768185, -0.05232131481170654, -0.004096691962331533, -0.007094188593327999, -0.014169877395033836, 0.0066404095850884914, -0.03071991540491581, -0.03866276144981384, -0.0035881614312529564, -0.034072283655405045, -0.0030499121639877558, 0.04113839939236641, -0.03961390256881714, -0.016827020794153214, 0.06037154793739319, 0.05211566016077995, 0.017159515991806984, 0.0395420640707016, -0.04115809500217438, 0.03320007771253586, -0.004044809378683567, 0.03738415241241455, 0.04300661012530327, -0.030422693118453026, 0.009513400495052338, -0.062261443585157394, 0.01942770928144455, 0.004391739144921303, -0.0002464582212269306, 0.024875206872820854, 0.01725439913570881, -0.0003349800535943359, 0.03741419315338135, -0.045099470764398575, -0.007478261366486549, 0.010805761441588402, 0.025592755526304245, -0.020368751138448715, -3.797012323047966e-05, -0.009736633859574795, 0.003419764805585146, 0.0063551864586770535, -0.019918199628591537, -0.04693856090307236, -0.056665875017642975, -0.014963293448090553, -0.005977965425699949, -0.04330020025372505, -0.013299407437443733, 0.104472316801548, 0.017137950286269188, -0.012480603531002998, -0.005291528068482876, -0.023958327248692513, -0.020108332857489586, -0.018054582178592682, 0.006818922236561775, 0.04811311885714531, -0.02875344082713127, 0.02814468741416931, 0.047545380890369415, 0.014695791527628899, 0.004492319654673338, 0.0195725467056036, 0.022069979459047318, -0.013999206013977528, -0.011690443381667137, -0.034768056124448776, -0.012231246568262577, 0.03560008108615875, 0.01626993529498577, 0.010947519913315773, -0.013104813173413277, -0.02605627290904522, 0.020580213516950607, 0.049011602997779846, -0.027183985337615013, -0.0002622309548314661, 0.007648410275578499, 0.008557559922337532, 0.01915810815989971, -0.0182334091514349, 0.011342554353177547, -0.005060755182057619, 0.004314980003982782, -0.0548882819712162, 0.032402411103248596, -0.013591684401035309, -0.027988998219370842, 0.025257233530282974, 0.08489073812961578, -0.038152698427438736, -0.006190582178533077, 0.00961056537926197, 0.019834544509649277, 0.005309958476573229, 0.025110825896263123, 0.06395624577999115, -0.015986453741788864, 0.004847925156354904, 0.004686206113547087, -0.030512848868966103, 0.017123263329267502, -0.005845779553055763, -0.040031153708696365, -0.04034627601504326, -0.0018967112991958857, -0.018999209627509117, 0.026728956028819084, -0.02753131464123726, 0.0214425977319479, -0.017784051597118378, 0.0182205680757761, -0.019967470318078995, -0.02322183921933174, -0.02812507562339306, -0.0005207994836382568, -0.0683155283331871, 0.02765846811234951, -0.013857276178896427, -0.031094294041395187, -0.03983500599861145, -0.05021661892533302, -0.0241387989372015, 0.000384185288567096, 0.03978801891207695, 0.009279894642531872, 0.007883483543992043, -0.02893264777958393, 0.014865736477077007, 0.03592270612716675, 0.013636316172778606, -0.018856344744563103, 0.01164412871003151, -0.04061327874660492, -0.011752496473491192, 0.09227494150400162, 0.02551959455013275, 0.002188882790505886, 0.00452767126262188, -0.004057068377733231, 0.012842568568885326, 0.011094445362687111, -0.00412759417667985, -0.03709394112229347, -0.036031000316143036, -0.03701544180512428, 0.021000754088163376, -0.018227268010377884, -0.0494655966758728, 0.02437918446958065, -0.04419253394007683, 0.013316667638719082, -0.054867252707481384, -0.032495710998773575, 0.013457064516842365, 0.016160208731889725, -0.06263718008995056, -0.012811697088181973, -0.004263004288077354, -0.007322543300688267, -0.019624482840299606, 0.0493955984711647, 0.006853344384580851, -0.02352350763976574, 0.020931310951709747, -0.02332388609647751, 0.013011261820793152, -0.08014506101608276, -0.004195046611130238, 0.018536949530243874, -0.018867691978812218, 0.007840055972337723, -0.032474830746650696, 0.008680294267833233, 0.003912761807441711, -0.003328605554997921, 0.018618935719132423, -0.008625950664281845, -0.043542299419641495, -0.01665305159986019, 0.0019589520525187254, 0.013131042942404747, -0.011729132384061813, -0.02015797235071659, 0.03988592326641083, 0.0007483178051188588, 0.00879806000739336, 0.015851754695177078, 0.0284701120108366, -0.018446410074830055, -0.027736438438296318, 0.011305084452033043, -0.0062957764603197575, 0.02768491953611374, -0.018135225400328636, -0.012330882251262665, 0.03965889289975166, 0.0009179512853734195, 0.022739432752132416, 0.002467096084728837, -0.03945978358387947, -0.009546080604195595, 0.002951553324237466, -0.04093503579497337, -0.00687542324885726, 0.03648732230067253, 0.03577357530593872, -0.013395699672400951, -0.0401000902056694, 0.023606082424521446, 0.0072841704823076725, -0.04742323234677315, -0.02234596200287342, -0.02231696806848049, -0.01588258519768715, 0.011940231546759605, -0.017910204827785492, -0.04067183658480644, 0.005327610764652491, -0.02457513101398945, -0.03198985010385513, -0.009140375070273876, 0.04227600246667862, -0.020596295595169067, -0.013705831952393055, 0.007519285660237074, 0.052600983530282974, 0.01937912218272686, -0.009908088482916355, 0.041460584849119186, 0.07075900584459305, 0.017854318022727966, 0.02316075749695301, -0.019012464210391045, -0.01705051399767399, 0.007843131199479103, -0.026490869000554085, 0.03243795782327652, -0.027725858613848686, 0.0018979518208652735, -0.0065591284073889256, 0.033861998468637466, -0.010906834155321121, -0.012489201501011848, -0.014484073966741562, -0.01235270407050848, -0.001568885170854628, 0.0021487639751285315, -0.04391244426369667, 0.03136162459850311, 0.0036216911394149065, -0.018535785377025604, 0.06117727980017662, -0.029837725684046745, -0.0013887917157262564, -0.03710022568702698, 0.012441400438547134, -0.02611059881746769, 0.024695133790373802, -0.027953466400504112, 0.04513581842184067, -0.02906392142176628, 0.03417070955038071, 0.013743322342634201, -0.06210663542151451, -0.0023300384636968374, -0.06603989005088806, -0.060670915991067886, -0.03355098515748978, -0.00354968779720366, -0.0027486984618008137, -0.015013745054602623, -0.0314398892223835, -0.01756134070456028, -0.03344007581472397, -0.018557654693722725, -0.0113625917583704, 0.0009124195203185081, 0.05245646834373474, 0.005571914371103048, 0.015516715124249458, -0.06495673954486847, 0.008443706668913364, -0.01756276749074459, 0.007544884458184242, -0.008536890149116516, 0.05546316131949425, -0.028141263872385025, 0.04462819546461105, -0.027346888557076454, 0.01101172436028719, 0.019060706719756126, -0.053637970238924026, -0.028618261218070984, 0.0021957901772111654, 0.011273976415395737, -0.045081425458192825, 0.004120359197258949, 0.047296952456235886, -0.028809932991862297, -0.011546961031854153, 0.0029905172996222973, 0.029401354491710663, 0.03742263466119766, -0.019216317683458328, 0.07143064588308334, 0.008513729088008404, -0.004499515518546104, 0.0005289442487992346, 0.006982363294810057, 0.034538038074970245, 0.0032306339126080275, -0.023092051967978477, 0.002168135019019246, -0.02535247430205345, -0.023123513907194138, -0.012668092735111713, -0.023713408038020134, -0.04276563599705696, 0.0266264621168375, -0.029716704040765762, 0.016310160979628563, 0.015258628875017166, -0.04286142811179161, 0.010202176868915558, -0.0001591469335835427, 0.0011238806182518601, -0.02886301279067993, -0.02783663012087345, -0.026373520493507385, 0.0011528418399393559, -0.004509687423706055, -0.03611471876502037, -0.0036315342877060175, -0.029402250424027443, 0.00035364495124667883, -0.0074089933186769485, 0.05850912258028984, -0.13799598813056946, -0.007650678511708975, -0.04991765692830086, 0.016659675166010857, -0.012742400169372559, 0.01091329287737608, 0.009842702187597752, -0.006873811595141888, 0.026915598660707474, -0.03286159411072731, 0.02094394527375698, 0.03060835413634777, -0.008007021620869637, -0.01886441744863987, -0.023143405094742775, 0.012730080634355545, 0.014298013411462307, -0.0382293201982975, 0.026137037202715874, 0.045487675815820694, 0.007223978638648987, -0.008880837820470333, 0.03312412276864052, 0.04787503555417061, -0.019144166260957718, 0.016261456534266472, 0.027027886360883713, -0.05125186964869499, -0.042524438351392746, 0.002058454556390643, 0.01573660597205162, -0.031099997460842133, 0.02530081383883953, 0.07731278240680695, 0.028186149895191193, 0.0003383165749255568, 0.017788425087928772, -0.0219590961933136, 0.0017426623962819576, -0.010091501288115978, 0.027951547876000404, 0.019085541367530823, 0.0029428524430841208, 0.0304928719997406, 0.02549837715923786, 0.030762452632188797, -0.011491233482956886, -0.02290225960314274, -0.03902384266257286, 0.04108182340860367, 0.022290123626589775, 0.007105810102075338, -0.017532093450427055, -0.017410751432180405, 0.01855049841105938, -0.013575110584497452, -0.06661755591630936, 0.008891388773918152, -0.007470222655683756, 0.018780875951051712, -0.0009254112374037504, 0.06447142362594604, -0.03462677821516991, -0.0327063649892807, 0.02190236933529377, 0.015230637975037098, -0.016310228034853935, 0.010544154793024063, 0.011073498986661434, 0.05577990412712097, 0.004710448905825615, -0.005108413752168417, -0.061971984803676605, 0.003159069921821356, 0.03392581269145012, 0.007084724493324757, 0.03466435894370079, 0.007555319927632809, -0.0201389342546463, -0.0006968396482989192, 0.009451552294194698, -0.031260162591934204, -0.026415586471557617, 0.03687139227986336, 0.05550394952297211, 0.005329398438334465, 0.012171629816293716, 0.026362089440226555, -0.020933646708726883, -0.009156790561974049, -0.03943032771348953, -0.032534755766391754, -0.04177983105182648, -0.027840733528137207, -0.02842477709054947, 0.0648694783449173, -0.009247605688869953, -0.0009863231098279357, 0.01735462248325348, 0.02360459789633751, 5.730851262342185e-05, 0.046923570334911346, 0.007887843064963818, 0.00146735820453614, -0.001968201482668519, 0.046751875430345535, 0.048673611134290695, -0.009076161310076714, -0.024668430909514427, -0.015868153423070908, -0.037026870995759964, -0.018736951053142548, 0.014727459289133549, 0.010759090073406696, -0.08521942049264908, -0.04541047662496567, 0.04303622990846634, 0.026724614202976227, 0.002500806702300906, 0.008198993280529976, -0.0024820829275995493, 0.022031668573617935, -0.029763594269752502, -0.028043217957019806, 0.055475689470767975, -0.0026581042911857367, 0.0034105877857655287, 0.0036796461790800095, -0.004926052410155535, 0.007021741475909948, -0.031766731292009354, -0.009929551742970943, 0.06109190732240677, -0.015907565131783485, 0.034420400857925415, -0.027147363871335983, -0.041329607367515564, 0.028859790414571762, -0.009855987504124641, 0.0021713748574256897, -0.009869569912552834, -0.028182946145534515, -0.030204609036445618, -0.0002501726266928017, -0.021057626232504845, -0.027081362903118134, 0.03307631239295006, 0.006927634589374065, -0.01454859972000122, -0.021541450172662735, 0.0020516894292086363, 0.011932030320167542, -0.0013140103546902537, 0.049434155225753784, -0.027843013405799866, 0.007025744765996933, 0.03559555485844612, 0.0030521973967552185, -0.03550810366868973, 0.0913001075387001, 0.03699982166290283, -0.08040182292461395, -0.011764819733798504, 0.01715586706995964, 0.0332111120223999, 0.011027165688574314, -0.015110758133232594, -0.007722759153693914, -0.024837885051965714, 0.03457626700401306, 0.05977080762386322, 0.021423209458589554, -0.017850138247013092, -0.01850031316280365, 0.05543960630893707, -0.016384385526180267, -0.00011213312245672569, 0.06244954839348793, 0.04231913387775421, 0.005957667250186205, 0.01424225140362978, -0.012172701768577099, 0.03378792107105255, 0.04249247536063194, 0.01461302861571312, -0.02132389135658741, 0.020464694127440453, -0.000609060749411583, -0.036450181156396866, -0.005969231948256493, -0.022693831473588943, -0.01168141607195139, 0.06766331195831299, -0.03592768684029579, 0.059246283024549484, 0.03684958815574646, -0.006587459705770016, 0.02873178757727146, -0.011334192007780075, 0.035144709050655365, -0.020501600578427315, -0.0040941741317510605, -0.029132885858416557, -0.034014392644166946, 0.000859632680658251, -0.014205416664481163, -0.019325021654367447, -0.03353015333414078, -0.02105088159441948, 0.04270732402801514, -0.0642903745174408, 0.021187452599406242, -0.051642950624227524, 0.014489516615867615, -0.0029411078430712223, -0.06217116862535477, 0.044792745262384415, 0.0034633360337466, -0.017389759421348572, 0.00904716458171606, 0.02523651160299778, 0.0368337444961071, 0.01841951720416546, -0.0593671016395092, -0.016044454649090767, 0.002134863520041108, -0.010845683515071869, 0.024514880031347275, 0.016255604103207588, 0.00870705209672451, 0.00039707613177597523, -0.019276797771453857, -0.013286140747368336, 0.017134785652160645, 0.040975119918584824, 0.010802754200994968, 0.014539599418640137, 0.008890983648598194, 0.005284434650093317, -0.023783467710018158, -0.005616339854896069, -0.003780483966693282, 0.011218789033591747, 0.017844833433628082], "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "47a66a1a-6d36-4f9e-bafe-bcbc99e118ca", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "0d98989d455f942df670f85f81116f71a4d5aa2ab3c8b201201d85b4e4ad98f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Source Documents Global Answer text extraction and chunking Text Chunks domaintailored summarization Community Answers queryfocused summarization Community Summaries domaintailored summarization community detection Graph CommunitiesIndexing TimePipeline StageQuery TimeFigure 1 Graph RAG pipeline using an LLMderived graph index of source document text This index spans nodes eg entities edges eg relationships and covariates eg claims that have been detected extracted and summarized by LLM prompts tailored to the domain of the dataset Community detection eg Leiden Traag et al 2019 is used to partition the graph index into groups of elements nodes edges covariates that the LLM can summarize in parallel at both indexing time and query time The global answer to a given query is produced using a final round of queryfocused summarization over all community summaries reporting relevance to that querya motivated continuous effort to understand connections which can be among people places and events in order to anticipate their trajectories and act effectively Klein et al 2006a Supporting humanled sensemaking over entire text corpora however needs a way for people to both apply and refine their mental model of the data Klein et al 2006b by asking questions of a global nature Retrievalaugmented generation RAG Lewis et al 2020 is an established approach to answering user questions over entire datasets but it is designed for situations where these answers are contained locally within regions of text whose retrieval provides sufficient grounding for the generation taskInstead a more appropriate task framing is queryfocused summarization QFS Dang 2006 and in particular queryfocused abstractive summarization that generates natural language summaries and not just concatenated excerpts Baumel et al 2018 Laskar et al 2020 Yao et al 2017 In recent years however such distinctions between summarization tasks that are abstractive versus extractive generic versus queryfocused and singledocument versus multidocument have become less relevant While early applications of the transformer architecture showed substantial improvements on the stateoftheart for all such summarization tasks Goodwin et al 2020 Laskar et al 2022 Liu and Lapata 2019 these tasks are now trivialized by modern LLMs including the GPT Achiam et al 2023 Brown et al 2020 Llama Touvron et al 2023 and Gemini Anil et al 2023 series all of which can use incontext learning to summarize any content provided in their context windowThe challenge remains however for queryfocused abstractive summarization over an entire corpus Such volumes of text can greatly exceed the limits of LLM context windows and the expansion of such windows may not be enough given that information can be lost in the middle of longer contexts Kuratov et al 2024 Liu et al 2023 In addition although the direct retrieval of text chunks in nave RAG is likely inadequate for QFS tasks it is possible that an alternative form of preindexing could support a new RAG approach specifically targeting global summarizationIn this paper we present a Graph RAG approach based on global summarization of an LLMderived knowledge graph Figure 1 In contrast with related work that exploits the structured retrieval and traversal affordances of graph indexes subsection 42 we focus on a previously unexplored quality of graphs in this context their inherent modularity Newman 2006 and the ability of community detection algorithms to partition graphs into modular communities of closelyrelated nodes eg Louvain Blondel et al 2008 Leiden Traag et al 2019 LLMgenerated summaries of these", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3864, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "a7badba9-3d3b-4e72-a766-db7d7c8814f8", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "276af327-93a9-4532-aa29-c486b5f30cab", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "c2145fd838d089d74f0652df224e5f18629ac6d1fec1a2283cf9ca6f0b8cb76a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Entity references detected30000600 chunk size   200002400 chunk size   10000    00123Figure 2 How the entity references detected in the HotPotQA dataset Yang et al 2018 varies with chunk size and gleanings for our generic entity extraction prompt with gpt4turboCommunity descriptions provide complete coverage of the underlying graph index and the input documents it represents Queryfocused summarization of an entire corpus is then made possible using a mapreduce approach first using each community summary to answer the query independently and in parallel then summarizing all relevant partial answers into a final global answerTo evaluate this approach we used an LLM to generate a diverse set of activitycentered sensemaking questions from short descriptions of two representative realworld datasets containing podcast transcripts and news articles respectively For the target qualities of comprehensiveness diversity and empowerment defined in subsection 34 that develop understanding of broad issues and themes we both explore the impact of varying the hierarchical level of community summaries used to answer queries as well as compare to nave RAG and global mapreduce summarization of source texts We show that all global approaches outperform nave RAG on comprehensiveness and diversity and that Graph RAG with intermediate and lowlevel community summaries shows favorable performance over source text summarization on these same metrics at lower token costs 2 Graph RAG Approach  PipelineWe now unpack the highlevel data flow of the Graph RAG approach Figure 1 and pipeline describing key design parameters techniques and implementation details for each step 21 Source Documents  Text ChunksA fundamental design decision is the granularity with which input texts extracted from source documents should be split into text chunks for processing In the following step each of these chunks will be passed to a set of LLM prompts designed to extract the various elements of a graph index Longer text chunks require fewer LLM calls for such extraction but suffer from the recall degradation of longer LLM context windows Kuratov et al 2024 Liu et al 2023 This behavior can be observed in Figure 2 in the case of a single extraction round ie with zero gleanings on a sample dataset HotPotQA Yang et al 2018 using a chunk size of 600 token extracted almost twice as many entity references as when using a chunk size of 2400 While more references are generally better any extraction process needs to balance recall and precision for the target activity 22 Text Chunks  Element InstancesThe baseline requirement for this step is to identify and extract instances of graph nodes and edges from each chunk of source text We do this using a multipart LLM prompt that first identifies all entities in the text including their name type and description before identifying all relationships between clearlyrelated entities including the source and target entities and a description of their relationship Both kinds of element instance are output in a single list of delimited tuples The primary opportunity to tailor this prompt to the domain of the document corpus lies in the choice of fewshot examples provided to the LLM for incontext learning Brown et al 2020", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3424, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "fcf90fc9-af5b-4468-9202-3cc55a77b5eb", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4cd05d7-6566-4493-8c4b-a480942d2c2d", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "f0d060d62a0acaba9afe4f4a318589437383f4bdb7b5dc33a054e2ac106f7c19", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example while our default prompt extracting the broad class of named entities like people places and organizations is generally applicable domains with specialized knowledge eg science medicine law will benefit from fewshot examples specialized to those domains We also support a secondary extraction prompt for any additional covariates we would like to associate with the extracted node instances Our default covariate prompt aims to extract claims linked to detected entities including the subject object type description source text span and start and end dates To balance the needs of efficiency and quality we use multiple rounds of gleanings up to a specified maximum to encourage the LLM to detect any additional entities it may have missed on prior extraction rounds This is a multistage process in which we first ask the LLM to assess whether all entities were extracted using a logit bias of 100 to force a yesno decision If the LLM responds that entities were missed then a continuation indicating that MANY entities were missed in the last extraction encourages the LLM to glean these missing entities This approach allows us to use larger chunk sizes without a drop in quality Figure 2 or the forced introduction of noise 23 Element Instances  Element SummariesThe use of an LLM to extract descriptions of entities relationships and claims represented in source texts is already a form of abstractive summarization relying on the LLM to create independently meaningful summaries of concepts that may be implied but not stated by the text itself eg the presence of implied relationships To convert all such instancelevel summaries into single blocks of descriptive text for each graph element ie entity node relationship edge and claim covariate requires a further round of LLM summarization over matching groups of instances A potential concern at this stage is that the LLM may not consistently extract references to the same entity in the same text format resulting in duplicate entity elements and thus duplicate nodes in the entity graph However since all closelyrelated communities of entities will be detected and summarized in the following step and given that LLMs can understand the common entity behind multiple name variations our overall approach is resilient to such variations provided there is sufficient connectivity from all variations to a shared set of closelyrelated entities Overall our use of rich descriptive text for homogeneous nodes in a potentially noisy graph structure is aligned with both the capabilities of LLMs and the needs of global queryfocused summarization These qualities also differentiate our graph index from typical knowledge graphs which rely on concise and consistent knowledge triples subject predicate object for downstream reasoning tasks 24 Element Summaries  Graph CommunitiesThe index created in the previous step can be modelled as an homogeneous undirected weighted graph in which entity nodes are connected by relationship edges with edge weights representing the normalized counts of detected relationship instances Given such a graph a variety of community detection algorithms may be used to partition the graph into communities of nodes with stronger connections to one another than to the other nodes in the graph eg see the surveys by Fortunato 2010 and Jin et al 2021 In our pipeline we use Leiden Traag et al 2019 on account of its ability to recover hierarchical community structure of largescale graphs efficiently Figure 3 Each level of this hierarchy provides a community partition that covers the nodes of the graph in a mutuallyexclusive collectiveexhaustive way enabling divideandconquer global summarization 25 Graph Communities  Community SummariesThe next step is to create reportlike summaries of each community in the Leiden hierarchy using a method designed to scale to very large datasets These summaries are independently useful in their own right as a way to understand the global structure and semantics of the dataset and may themselves be used to make sense of a corpus in the absence of a question For example a user may scan through community summaries at one level looking for general themes of interest then follow links to the reports at the lower level that provide more details for each of the subtopics Here however we focus on their utility as part of a graphbased index used for answering global queries Community summaries are generated in the following way", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4609, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "1381d50a-9672-41b5-a22c-449efc28e89a", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cceb9a1-b140-4bbc-ad5e-20f4323a0107", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "ac9f881517d4c766c291129ba7e606d490f13d2d7e8491e254aab5fbd88b647e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Figure 3 Graph communities detected using the Leiden algorithm Traag et al 2019 over the MultiHopRAG Tang and Yang 2024 dataset as indexedCircles represent entity nodes with size proportional to their degree Node layout was performed via OpenORD Martin et al 2011 and Force Atlas 2 Jacomy et al 2014 Node colors represent entity communities shown at two levels of hierarchical clustering a Level 0 corresponding to the hierarchical partition with maximum modularity and b Level 1 which reveals internal structure within these rootlevel communities  Leaflevel communitiesThe element summaries of a leaflevel community nodes edges covariates are prioritized and then iteratively added to the LLM context window until the token limit is reached The prioritization is as follows for each community edge in decreasing order of combined source and target node degree ie overall prominence add descriptions of the source node target node linked covariates and the edge itself  Higherlevel communitiesIf all element summaries fit within the token limit of the context window proceed as for leaflevel communities and summarize all element summaries within the community Otherwise rank subcommunities in decreasing order of element summary tokens and iteratively substitute subcommunity summaries shorter for their associated element summaries longer until fit within the context window is achieved 26 Community Summaries  Community Answers  Global AnswerGiven a user query the community summaries generated in the previous step can be used to generate a final answer in a multistage process The hierarchical nature of the community structure also means that questions can be answered using the community summaries from different levels raising the question of whether a particular level in the hierarchical community structure offers the best balance of summary detail and scope for general sensemaking questions evaluated in section 3For a given community level the global answer to any user query is generated as follows  Prepare community summariesCommunity summaries are randomly shuffled and divided into chunks of prespecified token size This ensures relevant information is distributed across chunks rather than concentrated and potentially lost in a single context window  Map community answersGenerate intermediate answers in parallel one for each chunk The LLM is also asked to generate a score between 0100 indicating how helpful the generated answer is in answering the target question Answers with score 0 are filtered out  Reduce to global answerIntermediate community answers are sorted in descending order of helpfulness score and iteratively added into a new context window until the token limit is reached This final context is used to generate the global answer returned to the user5", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2927, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "7ee2e4ff-4f0e-4ba1-a84a-3cf5119499cb", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e1f2ac7-be0e-4ed6-a484-d1ad150300d5", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "03de13e4bf63ab5f16e12a89dd88f40e20cc3ddbdb9dc675b80a93fd4f7782e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " DatasetExample activity framing and generation of global sensemaking questions PodcastUser A tech journalist looking for insights and trends in the tech industryTask Understanding how tech leaders view the role of policy and regulation Questions1 Which episodes deal primarily with tech policy and government regulation2 How do guests perceive the impact of privacy laws on technology development3 Do any guests discuss the balance between innovation and ethical considerations4 What are the suggested changes to current policies mentioned by the guests5 Are collaborations between tech companies and governments discussed and how NewsUser Educator incorporating current affairs into curriculaTask Teaching about health and wellness Questions1 What current topics in health can be integrated into health education curricula2 How do news articles address the concepts of preventive medicine and wellness3 Are there examples of health articles that contradict each other and if so why4 What insights can be gleaned about public health priorities based on news coverage5 How can educators use the dataset to highlight the importance of health literacy Table 1Examples of potential users tasks and questions generated by the LLM based on short descriptions of the target datasets Questions target global understanding rather than specific details Evaluation 31 DatasetsWe selected two datasets in the one million token range each equivalent to about 10 novels of text and representative of the kind of corpora that users may encounter in their real world activities Podcast transcripts Compiled transcripts of podcast conversations between Kevin Scott Microsoft CTO and other technology leaders Behind the Tech Scott 2024 Size 1669  600token text chunks with 100token overlaps between chunks 1 million tokens News articles Benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories including entertainment business sports technology health and science MultiHopRAG Tang and Yang 2024 Size 3197  600token text chunks with 100token overlaps between chunks 17 million tokens 32 QueriesMany benchmark datasets for opendomain question answering exist including HotPotQA Yang et al 2018 MultiHopRAG Tang and Yang 2024 and MTBench Zheng et al 2024 However the associated question sets target explicit fact retrieval rather than summarization for the purpose of data sensemaking ie the process though which people inspect engage with and contextualize data within the broader scope of realworld activities Koesten et al 2021 Similarly methods for extracting latent summarization queries from source texts also exist Xu and Lapata 2021 but such extracted questions can target details that betray prior knowledge of the textsTo evaluate the effectiveness of RAG systems for more global sensemaking tasks we need questions that convey only a highlevel understanding of dataset contents and not the details of specific texts We used an activitycentered approach to automate the generation of such questions given a short description of a dataset we asked the LLM to identify N potential users and N tasks per user then for each user task combination we asked the LLM to generate N questions that require understanding of the entire corpus For our evaluation a value of N  5 resulted in 125 test questions per dataset Table 1 shows example questions for each of the two evaluation datasets", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "40262df2-ed20-471a-b375-e3a1e2f4cd42", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b6a62eab-6554-4801-b553-b404426322d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "53d7ebb2b814bf4fe0c445af27b252fa7000124aeff34619796ffe6c12b4ed15", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " 33 ConditionsWe compare six different conditions in our analysis including Graph RAG using four levels of graph communities C0 C1 C2 C3 a text summarization method applying our mapreduce approach directly to source texts TS and a nave semantic search RAG approach SS CO Uses rootlevel community summaries fewest in number to answer user queries C1 Uses highlevel community summaries to answer queries These are subcommunities of C0 if present otherwise C0 communities projected down C2 Uses intermediatelevel community summaries to answer queries These are subcommunities of C1 if present otherwise C1 communities projected down C3 Uses lowlevel community summaries greatest in number to answer queries These are subcommunities of C2 if present otherwise C2 communities projected down TS The same method as in subsection 26 except source texts rather than community summaries are shuffled and chunked for the mapreduce summarization stages SS An implementation of nave RAG in which text chunks are retrieved and added to the available context window until the specified token limit is reachedThe size of the context window and the prompts used for answer generation are the same across all six conditions except for minor modifications to reference styles to match the types of context information used Conditions only differ in how the contents of the context window are createdThe graph index supporting conditions C0C3 was created using our generic prompts for entity and relationship extraction only with entity types and fewshot examples tailored to the domain of the data The graph indexing process used a context window size of 600 tokens with 1 gleaning for the Podcast dataset and 0 gleanings for the News dataset 34 MetricsLLMs have been shown to be good evaluators of natural language generation achieving stateoftheart or competitive results compared against human judgements Wang et al 2023a Zheng et al 2024 While this approach can generate referencebased metrics when gold standard answers are known it is also capable of measuring the qualities of generated texts eg fluency in a referencefree style Wang et al 2023a as well as in headtohead comparison of competing outputs LLMasajudge Zheng et al 2024 LLMs have also shown promise at evaluating the performance of conventional RAG systems automatically evaluating qualities like context relevance faithfulness and answer relevance RAGAS Es et al 2023Given the multistage nature of our Graph RAG mechanism the multiple conditions we wanted to compare and the lack of gold standard answers to our activitybased sensemaking questions we decided to adopt a headtohead comparison approach using an LLM evaluator We selected three target metrics capturing qualities that are desirable for sensemaking activities as well as a control metric directness used as an indicator of validity Since directness is effectively in opposition to comprehensiveness and diversity we would not expect any method to win across all four metricsOur headtohead measures computed using an LLM evaluator are as follows Comprehensiveness How much detail does the answer provide to cover all aspects and details of the question Diversity How varied and rich is the answer in providing different perspectives and insights on the question Empowerment How well does the answer help the reader understand and make informed judgements about the topic Directness How specifically and clearly does the answer address the questionFor our evaluation the LLM is provided with the question target metric and a pair of answers and asked to assess which answer is better according to the metric as well as why It returns the winner if one exists otherwise a tie if they are fundamentally similar and the differences are negligible To account for the stochasticity of LLMs we run each comparison five times and use mean scores Table 2 shows an example of LLMgenerated assessment", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4089, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "e149a73c-d513-4ce8-9cd2-329b55fe389f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f5085ed6-51f5-42b5-b3f9-dc86c09b5f72", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "f5cfdb831ff2a7c26ba9124d2b9676cbd5cd6956da9b19fda1ec07ee3e2d3411", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Overview of Prominent Public Figures in EntertainmentThe entertainment industry is vast and diverse encompassing film television music sports and digital media Certain public figures stand out due to their significant contributions and influence across these sectors The following summary highlights key individuals who are repeatedly mentioned in various entertainment articles reflecting their impact and presence within the industry Actors and Directors Public Figures in Controversy Musicians and Executives Athletes and Coaches Influencers and EntrepreneursThe repeated mention of these figures in entertainment articles signifies their ongoing relevance and the publics interest in their work Their influence spans across various aspects of entertainment from shaping cultural narratives in film and television to driving trends in music and digital media These individuals not only contribute to their respective fields but also influence the broader cultural landscape often becoming central figures in social discussions and public discourse Public Figures MentionedPublic figures who are repeatedly mentioned across various entertainment articles include Taylor Swift Travis Kelce Britney Spears and Justin Timberlake These individuals have been highlighted for various reasons ranging from their professional achievements to their personal livesTaylor Swift  Travis Kelce  Britney Spears  Justin Timberlake These figures are frequently covered due to their highprofile status and the publics interest in their careers and personal lives Their activities whether in music sports or personal relationships have significant cultural and economic impacts as evidenced by the media coverage and public reactions Comparative Analysis ComprehensivenessWinner1 Graph RAGAnswer 1 is better because it provides a more comprehensive and detailed list of public figures from a wider range of entertainment sectors including film television music sports gaming and digital media It also includes specific examples of their contributions and the impact they have on their respective fields as well as mentions of controversies and their implications Answer 2 while detailed in its coverage of a few individuals is limited to a smaller number of public figures and focuses primarily on their personal lives and relationships rather than a broad spectrum of their professional influence across the entertainment industry DiversityWinner1 Graph RAGAnswer 1 is better because it provides a more varied and rich response by covering a wide range of public figures from different sectors of the entertainment industry including film television music sports gaming and digital media It offers insights into the contributions and influence of these figures as well as controversies and their impact on public discourse The answer also cites specific data sources for each mentioned figure indicating a diverse range of evidence to support the claims In contrast Answer 2 focuses on a smaller group of public figures primarily from the music industry and sports and relies heavily on a single source for data which makes it less diverse in perspectives and insights EmpowermentWinner1 Graph RAGAnswer 1 is better because it provides a comprehensive and structured overview of public figures across various sectors of the entertainment industry including film television music sports and digital media It lists multiple individuals providing specific examples of their contributions and the context in which they are mentioned in entertainment articles along with references to data reports for each claim This approach helps the reader understand the breadth of the topic and make informed judgments without being misled In contrast Answer 2 focuses on a smaller group of public figures and primarily discusses their personal lives and relationships which may not provide as broad an understanding of the topic While Answer 2 also cites sources it does not match the depth and variety of Answer 1 DirectnessWinner2 Nave RAGAnswer 2 is better because it directly lists specific public figures who are repeatedly mentioned across various entertainment articles such as Taylor Swift Travis Kelce Britney Spears and Justin Timberlake and provides concise explanations for their frequent mentions Answer 1 while comprehensive includes a lot of detailed information about various figures in different sectors of entertainment which while informative does not directly answer the question with the same level of conciseness and specificity as Answer 2 Example Question for the News Article DatasetTable 2 Example question for the News article dataset with generated answers from Graph RAG C2 and Nave RAG as well as LLMgenerated assessments", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4909, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "cca54c95-f512-4626-af9b-87b57e2c759f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed1f6401-4b2b-4d20-a2e9-5bce80a45674", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "9860d87b59c78feec9c73c8b759c96787e0ca423f858756096aa0fc3ba131de6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Podcast transcriptsSSTSC0C1C2C3508372757879175050525756285050475051254853504850224350525048214449505250 Comprehensiveness Diversity Empowerment DirectnessSSTSC0C1C2C3508072757979205056596264284450484648254152504245213854585041213652555950Figure 4 Headtohead win rate percentages of row condition over column condition across two datasets four metrics and 125 questions per comparison each repeated five times and averaged The overall winner per dataset and metric is shown in bold Selfwin rates were not computed but are shown as the expected 50 for reference All Graph RAG conditions outperformed nave RAG on comprehensiveness and diversity Conditions C1C3 also showed slight improvements in answer comprehensiveness and diversity over TS global text summarization without a graph index 35 ConfigurationThe effect of context window size on any particular task is unclear especially for models like gpt4turbo with a large context size of 128k tokens Given the potential for information to be lost in the middle of longer contexts Kuratov et al 2024 Liu et al 2023 we wanted to explore the effects of varying the context window size for our combinations of datasets questions and metrics In particular our goal was to determine the optimum context size for our baseline condition SS and then use this uniformly for all querytime LLM use To that end we tested four context window sizes 8k 16k 32k and 64k Surprisingly the smallest context window size tested 8k was universally better for all comparisons on comprehensiveness average win rate of 581 while performing comparably with larger context sizes on diversity average win rate  524 and empowerment average win rate  513 Given our preference for more comprehensive and diverse answers we therefore used a fixed context window size of 8k tokens for the final evaluation 36 ResultsThe indexing process resulted in a graph consisting of 8564 nodes and 20691 edges for the Podcast dataset and a larger graph of 15754 nodes and 19520 edges for the News dataset Table 3 shows the number of community summaries at different levels of each graph community hierarchyGlobal approaches vs nave RAG As shown in Figure 4 global approaches consistently outperformed the nave RAG SS approach in both comprehensiveness and diversity metrics across datasets Specifically global approaches achieved comprehensiveness win rates between 7283 for Podcast transcripts and 7280 for News articles while diversity win rates ranged from 7582 and 6271 respectively Our use of directness as a validity test also achieved the expected results ie that nave RAG produces the most direct responses across all comparisons", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "506f756e-4371-4326-abb0-35816c7b966c", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec745805-b431-48b4-b82c-6107243d2d58", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e6b7d9fb1ef245bcbb4a510303f39719d87793fce80dcf3cd96102a63874ae4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "068c13ee-e8b8-43ef-ac8e-c515d07ef1d4", "node_type": "1", "metadata": {}, "hash": "7fc6de3f293b14cc332203d259657abd99adfb01c2ae0dd5487912ace031c875", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " Podcast Transcripts News ArticlesUnitsC0C1C2C3TS      3436796913101669     Tokens266572257565657207461001014611      Max26222558735100     Table 3 Number of context units community summaries for C0C3 and text chunks for TS corresponding token counts and percentage of the maximum token count Mapreduce summarization of source texts is the most resourceintensive approach requiring the highest number of context tokens Rootlevel community summaries C0 require dramatically fewer tokens per query 9x43xCommunity summaries vs source texts When comparing community summaries to source texts using Graph RAG community summaries generally provided a small but consistent improvement in answer comprehensiveness and diversity except for rootlevel summaries Intermediatelevel summaries in the Podcast dataset and lowlevel community summaries in the News dataset achieved comprehensiveness win rates of 57 and 64 respectively Diversity win rates were 57 for Podcast intermediatelevel summaries and 60 for News lowlevel community summaries Table 3 also illustrates the scalability advantages of Graph RAG compared to source text summarization for lowlevel community summaries C3 Graph RAG required 2633 fewer context tokens while for rootlevel community summaries C0 it required over 97 fewer tokens For a modest drop in performance compared with other global methods rootlevel Graph RAG offers a highly efficient method for the iterative question answering that characterizes sensemaking activity while retaining advantages in comprehensiveness 72 win rate and diversity 62 win rate over nave RAGEmpowerment Empowerment comparisons showed mixed results for both global approaches versus nave RAG SS and Graph RAG approaches versus source text summarization TS Adhoc LLM use to analyze LLM reasoning for this measure indicated that the ability to provide specific examples quotes and citations was judged to be key to helping users reach an informed understanding Tuning element extraction prompts may help to retain more of these details in the Graph RAG index 4 Related Work 41 RAG Approaches and SystemsWhen using LLMs RAG involves first retrieving relevant information from external data sources then adding this information to the context window of the LLM along with the original query Ram et al 2023 Nave RAG approaches Gao et al 2023 do this by converting documents to text splitting text into chunks and embedding these chunks into a vector space in which similar positions represent similar semantics Queries are then embedded into the same vector space with the text chunks of the nearest k vectors used as context More advanced variations exist but all solve the problem of what to do when an external dataset of interest exceeds the LLMs context windowAdvanced RAG systems include preretrieval retrieval postretrieval strategies designed to overcome the drawbacks of Nave RAG while Modular RAG systems include patterns for iterative and dynamic cycles of interleaved retrieval and generation Gao et al 2023 Our implementation of Graph RAG incorporates multiple concepts related to other systems For example our community summaries are a kind of selfmemory Selfmem Cheng et al 2024 for generationaugmented retrieval GAR Mao et al 2020 that facilitates future generation cycles while our parallel generation of community answers from these summaries is a kind of iterative IterRetGen Shao et al 2023 or federated FeB4RAG Wang et al 2024 retrievalgeneration strategy Other systems have also combined these concepts for multidocument summarization CAiRECOVID Su et al 2020 and multihop question answering ITRG Feng et al 2023 IRCoT Trivedi et al 2022 DSP Khattab et al 2022", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3951, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "068c13ee-e8b8-43ef-ac8e-c515d07ef1d4", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec745805-b431-48b4-b82c-6107243d2d58", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e6b7d9fb1ef245bcbb4a510303f39719d87793fce80dcf3cd96102a63874ae4c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "506f756e-4371-4326-abb0-35816c7b966c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "648d307ae672e34a712e5de4429768d283fa8f2405fdb3cd1d19ace89e259d93", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Our use of a hierarchical index and summarization also bears resemblance to further approaches such as generating a hierarchical index of text chunks by clustering the vectors of text embeddings RAPTOR Sarthi et al 2024 or generating a tree of clarifications to answer multiple interpretations of ambiguous questions Kim et al 2023 However none of these iterative or hierarchical approaches use the kind of selfgenerated graph index that enables Graph RAG", "mimetype": "text/plain", "start_char_idx": 3952, "end_char_idx": 4423, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "738095aa-f979-4836-9819-d21592789eba", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a486463-97aa-46b1-a190-cfc56fac532e", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "e1ad53ef9879cb94e58810412154c2d54d5c56d1dc74ab5a193ddf72c56a7abf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " 42 Graphs and LLMsUse of graphs in connection with LLMs and RAG is a developing research area with multiple directions already established These include using LLMs for knowledge graph creation Trajanoska et al 2023 and completion Yao et al 2023 as well as for the extraction of causal graphs Ban et al 2023 Zhang et al 2024 from source texts They also include forms of advanced RAG Gao et al 2023 where the index is a knowledge graph KAPING Baek et al 2023 where subsets of the graph structure GRetriever He et al 2024 or derived graph metrics GraphToolFormer Zhang 2023 are the objects of enquiry where narrative outputs are strongly grounded in the facts of retrieved subgraphs SURGE Kang et al 2023 where retrieved eventplot subgraphs are serialized using narrative templates FABULA Ranade and Joshi 2023 and where the system supports both creation and traversal of textrelationship graphs for multihop question answering Wang et al 2023b In terms of opensource software a variety of graph databases are supported by both the LangChain LangChain 2024 and LlamaIndex LlamaIndex 2024 libraries while a more general class of graphbased RAG applications is also emerging including systems that can create and reason over knowledge graphs in both Neo4J NaLLM Neo4J 2024 and NebulaGraph GraphRAG NebulaGraph 2024 formats Unlike our Graph RAG approach however none of these systems use the natural modularity of graphs to partition data for global summarization 5 DiscussionLimitations of evaluation approach Our evaluation to date has only examined a certain class of sensemaking questions for two corpora in the region of 1 million tokens More work is needed to understand how performance varies across different ranges of question types data types and dataset sizes as well as to validate our sensemaking questions and target metrics with end users Comparison of fabrication rates eg using approaches like SelfCheckGPT Manakul et al 2023 would also improve on the current analysisTradeoffs of building a graph index We consistently observed Graph RAG achieve the best headtohead results against other methods but in many cases the graphfree approach to global summarization of source texts performed competitively The realworld decision about whether to invest in building a graph index depends on multiple factors including the compute budget expected number of lifetime queries per dataset and value obtained from other aspects of the graph index including the generic community summaries and the use of other graphrelated RAG approachesFuture work The graph index rich text annotations and hierarchical community structure supporting the current Graph RAG approach offer many possibilities for refinement and adaptation This includes RAG approaches that operate in a more local manner via embeddingbased matching of user queries and graph annotations as well as the possibility of hybrid RAG schemes that combine embeddingbased matching against community reports before employing our mapreduce summarization mechanisms This rollup operation could also be extended across more levels of the community hierarchy as well as implemented as a more exploratory drill down mechanism that follows the information scent contained in higherlevel community summaries 6 ConclusionWe have presented a global approach to Graph RAG combining knowledge graph generation retrievalaugmented generation RAG and queryfocused summarization QFS to support human sensemaking over entire text corpora Initial evaluations show substantial improvements over a nave RAG baseline for both the comprehensiveness and diversity of answers as well as favorable comparisons to a global but graphfree approach using mapreduce source text summarization For situations requiring many global queries over the same dataset summaries of rootlevel communities in the entitybased graph index provide a data index that is both superior to nave RAG and achieves competitive performance to other global methods at a fraction of the token cost An opensource Pythonbased implementation of both global and local Graph RAG approaches is forthcoming at httpsakamsgraphrag", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4304, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "12fcb2d1-091e-472e-bfef-bec41ae99002", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b0ab76-1bc2-456b-84e0-e21eafb8667a", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "d40f5e08ccc0385a89d486d7fd64a36268ecfe3f99ff36816c2800ac232f9a0d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77a83051-73b5-4bde-a106-60b8b6b9668f", "node_type": "1", "metadata": {}, "hash": "3a7d68e0f78278d3511fc5b17e8d1d9f8778234c525f5fa4c416585d825a318f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " AcknowledgementsWe would also like to thank the following people who contributed to the work Alonso Guevara Fernndez Amber Hoak Andrs Morales Esquivel Ben Cutler Billie Rinaldi Chris Sanchez Chris Trevino Christine Caggiano David Tittsworth Dayenne de Souza Douglas Orbaker Ed Clark Gabriel NievesPonce Gaudy Blanco Meneses Kate Lytvynets Katy Smith Mnica Carvajal Nathan Evans Richard Ortega Rodrigo Racanicci Sarah Smith and Shane Solomon ReferencesAchiam J Adler S Agarwal S Ahmad L Akkaya I Aleman F L Almeida D Altenschmidt J Altman S Anadkat S et al 2023 Gpt4 technical report arXiv preprint arXiv230308774Anil R Borgeaud S Wu Y Alayrac JB Yu J Soricut R Schalkwyk J Dai A M Hauth A et al 2023 Gemini a family of highly capable multimodal models arXiv preprint arXiv231211805Baek J Aji A F and Saffari A 2023 Knowledgeaugmented language model prompting for zeroshot knowledge graph question answering arXiv preprint arXiv230604136Ban T Chen L Wang X and Chen H 2023 From query tools to causal architects Harnessing large language models for advanced causal discovery from dataBaumel T Eyal M and Elhadad M 2018 Query focused abstractive summarization Incorporating query relevance multidocument coverage and summary length constraints into seq2seq models arXiv preprint arXiv180107704Blondel V D Guillaume JL Lambiotte R and Lefebvre E 2008 Fast unfolding of communities in large networks Journal of statistical mechanics theory and experiment 200810P10008Brown T Mann B Ryder N Subbiah M Kaplan J D Dhariwal P Neelakantan A Shyam P Sastry G Askell A et al 2020 Language models are fewshot learners Advances in neural information processing systems 3318771901Cheng X Luo D Chen X Liu L Zhao D and Yan R 2024 Lift yourself up Retrievalaugmented text generation with selfmemory Advances in Neural Information Processing Systems 36Dang H T 2006 Duc 2005 Evaluation of questionfocused summarization systems In Proceedings of the Workshop on TaskFocused Summarization and Question Answering pages 4855Es S James J EspinosaAnke L and Schockaert S 2023 Ragas Automated evaluation of retrieval augmented generation arXiv preprint arXiv230915217Feng Z Feng X Zhao D Yang M and Qin B 2023 Retrievalgeneration synergy augmented large language models arXiv preprint arXiv231005149Fortunato S 2010 Community detection in graphs Physics reports 4863575174Gao Y Xiong Y Gao X Jia K Pan J Bi Y Dai Y Sun J and Wang H 2023 Retrievalaugmented generation for large language models A survey arXiv preprint arXiv231210997Goodwin T R Savery M E and DemnerFushman D 2020 Flight of the pegasus", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2978, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "77a83051-73b5-4bde-a106-60b8b6b9668f", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b0ab76-1bc2-456b-84e0-e21eafb8667a", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "d40f5e08ccc0385a89d486d7fd64a36268ecfe3f99ff36816c2800ac232f9a0d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "12fcb2d1-091e-472e-bfef-bec41ae99002", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "0fe02d611577c594359b49ff9ea7da0ec3495bd1658aed01a8ba94f61bcb44e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2020 Flight of the pegasus comparing transformers on fewshot and zeroshot multidocument abstractive summarization In Proceedings of COLING International Conference on Computational Linguistics volume 2020 page 5640 NIH Public AccessHe X Tian Y Sun Y Chawla N V Laurent T LeCun Y Bresson X and Hooi B 2024 Gretriever Retrievalaugmented generation for textual graph understanding and question answering arXiv preprint arXiv240207630", "mimetype": "text/plain", "start_char_idx": 2948, "end_char_idx": 3427, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "cc76f242-a34c-42e5-8af1-7297c8acc192", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6af52b0c-3a72-42e6-89f2-07b81abf16e1", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "3a235a4cc02e7cf4e41db1b376b4cda3e2520b617de0f5d61d5bcba9eba7c65b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d8290ca-d8a9-4101-b6a5-36c46e2698b3", "node_type": "1", "metadata": {}, "hash": "7ec39575dd9d00178090a1c51bacd0cc0f100e0f0c57dcab9f95e8c48bf04332", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " ReferencesJacomy M Venturini T Heymann S and Bastian M 2014 Forceatlas2 a continuous graph layout algorithm for handy network visualization designed for the gephi software PLoS ONE 96 e98679 httpsdoiorg101371journalpone0098679Jin D Yu Z Jiao P Pan S He D Wu J Philip S Y and Zhang W 2021 A survey of community detection approaches From statistical modeling to deep learning IEEE Transactions on Knowledge and Data Engineering 35211491170Kang M Kwak J M Baek J and Hwang S J 2023 Knowledge graphaugmented language models for knowledgegrounded dialogue generation arXiv preprint arXiv230518846Khattab O Santhanam K Li X L Hall D Liang P Potts C and Zaharia M 2022 Demonstratesearchpredict Composing retrieval and language models for knowledgeintensive nlp arXiv preprint arXiv221214024Kim G Kim S Jeon B Park J and Kang J 2023 Tree of clarifications Answering ambiguous questions with retrievalaugmented large language models arXiv preprint arXiv231014696Klein G Moon B and Hoffman R R 2006a Making sense of sensemaking 1 Alternative perspectives IEEE intelligent systems 2147073Klein G Moon B and Hoffman R R 2006b Making sense of sensemaking 2 A macrocognitive model IEEE Intelligent systems 2158892Koesten L Gregory K Groth P and Simperl E 2021 Talking datasetsunderstanding data sensemaking behaviours International journal of humancomputer studies 146102562Kuratov Y Bulatov A Anokhin P Sorokin D Sorokin A and Burtsev M 2024 In search of needles in a 11m haystack Recurrent memory finds what llms missLangChain 2024 Langchain graphs httpspythonlangchaincomdocsuse casesgraphLaskar M T R Hoque E and Huang J 2020 Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models In Advances in Artificial Intelligence 33rd Canadian Conference on Artificial Intelligence Canadian AI 2020 Ottawa ON Canada May 1315 2020 Proceedings 33 pages 342348 SpringerLaskar M T R Hoque E and Huang J X 2022 Domain adaptation with pretrained transformers for queryfocused abstractive text summarization Computational Linguistics 482279320Lewis P Perez E Piktus A Petroni F Karpukhin V Goyal N Kttler H Lewis M Yih Wt Rocktaschel T et al 2020 Retrievalaugmented generation for knowledgeintensive nlp tasks Advances in Neural Information Processing Systems 3394599474Liu N F Lin K Hewitt J Paranjape A Bevilacqua M Petroni F and Liang P 2023 Lost in the middle How language models use long contexts arXiv230703172Liu Y and Lapata M 2019 Hierarchical transformers for multidocument summarization arXiv preprint arXiv190513164LlamaIndex 2024 LlamaIndex Knowledge Graph Index", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3024, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "6d8290ca-d8a9-4101-b6a5-36c46e2698b3", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6af52b0c-3a72-42e6-89f2-07b81abf16e1", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "3a235a4cc02e7cf4e41db1b376b4cda3e2520b617de0f5d61d5bcba9eba7c65b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc76f242-a34c-42e5-8af1-7297c8acc192", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "a72af445eafd923f926c96422526a56786931cf14b52ea31943dc1e94898ae39", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "LlamaIndex 2024 LlamaIndex Knowledge Graph Index httpsdocsllamaindexaienstableexamplesindex structsknowledge graphKnowledgeGraphDemohtmlManakul P Liusie A and Gales M J 2023 Selfcheckgpt Zeroresource blackbox hallucination detection for generative large language models arXiv preprint arXiv230308896Mao Y He P Liu X Shen Y Gao J Han J and Chen W 2020 Generationaugmented retrieval for opendomain question answering arXiv preprint arXiv200908553Martin S Brown W M Klavans R and Boyack K 2011 Openord An opensource toolbox for large graph layout SPIE Conference on Visualization and Data Analysis VDAMicrosoft 2023 The impact of large language models on scientific discovery a preliminary study using gpt4", "mimetype": "text/plain", "start_char_idx": 2972, "end_char_idx": 3775, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "eb98d772-785b-43a8-a13b-40ec2036b3be", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfd503dd-865b-44fd-83a7-0895fb4cc3e7", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "b03e99c5e92862688bcda297d11c6ce05f8fe537448bbb4ddd89d777f475293f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "deeef575-0e6f-4604-a356-175f0b3de6d1", "node_type": "1", "metadata": {}, "hash": "763676edc73448e89b19b505821f4ef46046dbb64887a4dcf8137f9291d1a9a2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " ReferencesNebulaGraph 2024 Nebulagraph launches industryfirst graph rag Retrievalaugmented generation with llm based on knowledge graphs httpswwwnebulagraphiopostsgraphRAGNeo4J 2024 Project NaLLM httpsgithubcomneo4jNaLLMNewman M E 2006 Modularity and community structure in networks Proceedings of the national academy of sciences 1032385778582Ram O Levine Y Dalmedigos I Muhlgay D Shashua A LeytonBrown K and Shoham Y 2023 Incontext retrievalaugmented language models Transactions of the Association for Computational Linguistics 1113161331Ranade P and Joshi A 2023 Fabula Intelligence report generation using retrievalaugmented narrative construction arXiv preprint arXiv231013848Sarthi P Abdullah S Tuli A Khanna S Goldie A and Manning C D 2024 Raptor Recursive abstractive processing for treeorganized retrieval arXiv preprint arXiv240118059Scott K 2024 Behind the Tech httpswwwmicrosoftcomenusbehindthetechShao Z Gong Y Shen Y Huang M Duan N and Chen W 2023 Enhancing retrievalaugmented large language models with iterative retrievalgeneration synergy arXiv preprint arXiv230515294Su D Xu Y Yu T Siddique F B Barezi E J and Fung P 2020 Cairecovid A question answering and queryfocused multidocument summarization system for covid19 scholarly information management arXiv preprint arXiv200503975Tang Y and Yang Y 2024 MultiHopRAG Benchmarking retrievalaugmented generation for multihop queries arXiv preprint arXiv240115391Touvron H Martin L Stone K Albert P Almahairi A Babaei Y Bashlykov N Batra S Bhargava P Bhosale S et al 2023 Llama 2 Open foundation and finetuned chat models arXiv preprint arXiv230709288Traag V A Waltman L and Van Eck N J 2019 From Louvain to Leiden guaranteeing wellconnected communities Scientific Reports 91Trajanoska M Stojanov R and Trajanov D 2023 Enhancing knowledge graph construction using large language models ArXiv abs230504676Trivedi H Balasubramanian N Khot T and Sabharwal A 2022 Interleaving retrieval with chainofthought reasoning for knowledgeintensive multistep questions arXiv preprint arXiv221210509Wang J Liang Y Meng F Sun Z Shi H Li Z Xu J Qu J and Zhou J 2023a Is chatgpt a good nlg evaluator a preliminary study arXiv preprint arXiv230304048Wang S Khramtsova E Zhuang S and Zuccon G 2024 Feb4rag Evaluating federated search in the context of retrieval augmented generation arXiv preprint arXiv240211891Wang Y Lipka N Rossi R A Siu A Zhang R and Derr T 2023b Knowledge graph prompting for multidocument question answeringXu Y and Lapata M 2021", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2917, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "deeef575-0e6f-4604-a356-175f0b3de6d1", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfd503dd-865b-44fd-83a7-0895fb4cc3e7", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "b03e99c5e92862688bcda297d11c6ce05f8fe537448bbb4ddd89d777f475293f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb98d772-785b-43a8-a13b-40ec2036b3be", "node_type": "1", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "a759037e95fa5cca94c55f8918240421d2acedd1aaa05ba2c017c74f07f13e34", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Xu Y and Lapata M 2021 Text summarization with latent queries arXiv preprint arXiv210600104Yang Z Qi P Zhang S Bengio Y Cohen W W Salakhutdinov R and Manning C D 2018 HotpotQA A dataset for diverse explainable multihop question answering In Conference on Empirical Methods in Natural Language Processing EMNLPYao Jg Wan X and Xiao J 2017 Recent advances in document summarization Knowledge and Information Systems 53297336", "mimetype": "text/plain", "start_char_idx": 2888, "end_char_idx": 3375, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, {"__data__": {"id_": "768ab3bc-03e3-4545-928a-e0e2f13d9056", "embedding": null, "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68a01efd-b8fa-403c-ac0a-9f548ade6956", "node_type": "4", "metadata": {"file_path": "C:\\Users\\zrj\\PycharmProjects\\chatgpt\\datapool\\RAG_data\\graphRAG.pdf", "file_name": "graphRAG.pdf", "file_type": "application/pdf", "file_size": 6782285, "creation_date": "2024-12-18", "last_modified_date": "2024-12-18"}, "hash": "8ed714d99bbb0060e8422cf67e29353e0ccc875dda9cd5f403f06628698081ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": " ReferencesYao L Peng J Mao C and Luo Y 2023 Exploring large language models for knowledge graph completionZhang J 2023 Graphtoolformer To empower llms with graph reasoning ability via prompt augmented by chatgpt arXiv preprint arXiv230411116Zhang Y Zhang Y Gan Y Yao L and Wang C 2024 Causal graph discovery with retrievalaugmented generation based large language models arXiv preprint arXiv240215301Zheng L Chiang WL Sheng Y Zhuang S Wu Z Zhuang Y Lin Z Li Z Li D Xing E et al 2024 Judging llmasajudge with mtbench and chatbot arena Advances in Neural Information Processing Systems 36", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 687, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}]}}}